{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Experiment Name : .-Continual_True-online_False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from PIL import Image \n",
    "from arguments import parser \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "from datasets import create_dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from utils.metrics import MetricCalculator, loco_auroc\n",
    "from accelerate import Accelerator\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns \n",
    "from main import torch_seed\n",
    "\n",
    "\n",
    "\n",
    "torch_seed(42)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' \n",
    "default_setting = './configs/default/mvtecad.yaml'\n",
    "model_setting = './configs/model/cfgcad.yaml'\n",
    "cfg = parser(True,default_setting, model_setting)\n",
    "\n",
    "\n",
    "model  = __import__('models').__dict__[cfg.MODEL.method](\n",
    "        backbone = cfg.MODEL.backbone,\n",
    "        **cfg.MODEL.params\n",
    "        ).to('cuda')\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "loader_dict = {}\n",
    "accelerator = Accelerator()\n",
    "for cn in cfg.DATASET.class_names:\n",
    "    trainset, testset = create_dataset(\n",
    "        dataset_name  = cfg.DATASET.dataset_name,\n",
    "        datadir       = cfg.DATASET.datadir,\n",
    "        class_name    = cn,\n",
    "        img_size      = cfg.DATASET.img_size,\n",
    "        mean          = cfg.DATASET.mean,\n",
    "        std           = cfg.DATASET.std,\n",
    "        aug_info      = cfg.DATASET.aug_info,\n",
    "        **cfg.DATASET.get('params',{})\n",
    "    )\n",
    "    trainloader = DataLoader(\n",
    "        dataset     = trainset,\n",
    "        batch_size  = cfg.DATASET.batch_size,\n",
    "        num_workers = cfg.DATASET.num_workers,\n",
    "        shuffle     = True \n",
    "    )    \n",
    "\n",
    "    testloader = DataLoader(\n",
    "            dataset     = testset,\n",
    "            batch_size  = 8,\n",
    "            num_workers = cfg.DATASET.num_workers,\n",
    "            shuffle     = False \n",
    "        )    \n",
    "    \n",
    "    loader_dict[cn] = {'train':trainloader,'test':testloader}    \n",
    "# model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying learnable layers (focusing on nn.Linear/Conv2d, ignoring nn.LayerNorm)...\n",
      "Identified Learnable Layers: ['backbone._conv_stem', 'backbone._blocks.0._depthwise_conv', 'backbone._blocks.0._se_reduce', 'backbone._blocks.0._se_expand', 'backbone._blocks.0._project_conv', 'backbone._blocks.1._depthwise_conv', 'backbone._blocks.1._se_reduce', 'backbone._blocks.1._se_expand', 'backbone._blocks.1._project_conv', 'backbone._blocks.2._expand_conv', 'backbone._blocks.2._depthwise_conv', 'backbone._blocks.2._se_reduce', 'backbone._blocks.2._se_expand', 'backbone._blocks.2._project_conv', 'backbone._blocks.3._expand_conv', 'backbone._blocks.3._depthwise_conv', 'backbone._blocks.3._se_reduce', 'backbone._blocks.3._se_expand', 'backbone._blocks.3._project_conv', 'backbone._blocks.4._expand_conv', 'backbone._blocks.4._depthwise_conv', 'backbone._blocks.4._se_reduce', 'backbone._blocks.4._se_expand', 'backbone._blocks.4._project_conv', 'backbone._blocks.5._expand_conv', 'backbone._blocks.5._depthwise_conv', 'backbone._blocks.5._se_reduce', 'backbone._blocks.5._se_expand', 'backbone._blocks.5._project_conv', 'backbone._blocks.6._expand_conv', 'backbone._blocks.6._depthwise_conv', 'backbone._blocks.6._se_reduce', 'backbone._blocks.6._se_expand', 'backbone._blocks.6._project_conv', 'backbone._blocks.7._expand_conv', 'backbone._blocks.7._depthwise_conv', 'backbone._blocks.7._se_reduce', 'backbone._blocks.7._se_expand', 'backbone._blocks.7._project_conv', 'backbone._blocks.8._expand_conv', 'backbone._blocks.8._depthwise_conv', 'backbone._blocks.8._se_reduce', 'backbone._blocks.8._se_expand', 'backbone._blocks.8._project_conv', 'backbone._blocks.9._expand_conv', 'backbone._blocks.9._depthwise_conv', 'backbone._blocks.9._se_reduce', 'backbone._blocks.9._se_expand', 'backbone._blocks.9._project_conv', 'backbone._blocks.10._expand_conv', 'backbone._blocks.10._depthwise_conv', 'backbone._blocks.10._se_reduce', 'backbone._blocks.10._se_expand', 'backbone._blocks.10._project_conv', 'backbone._blocks.11._expand_conv', 'backbone._blocks.11._depthwise_conv', 'backbone._blocks.11._se_reduce', 'backbone._blocks.11._se_expand', 'backbone._blocks.11._project_conv', 'backbone._blocks.12._expand_conv', 'backbone._blocks.12._depthwise_conv', 'backbone._blocks.12._se_reduce', 'backbone._blocks.12._se_expand', 'backbone._blocks.12._project_conv', 'backbone._blocks.13._expand_conv', 'backbone._blocks.13._depthwise_conv', 'backbone._blocks.13._se_reduce', 'backbone._blocks.13._se_expand', 'backbone._blocks.13._project_conv', 'backbone._blocks.14._expand_conv', 'backbone._blocks.14._depthwise_conv', 'backbone._blocks.14._se_reduce', 'backbone._blocks.14._se_expand', 'backbone._blocks.14._project_conv', 'backbone._blocks.15._expand_conv', 'backbone._blocks.15._depthwise_conv', 'backbone._blocks.15._se_reduce', 'backbone._blocks.15._se_expand', 'backbone._blocks.15._project_conv', 'backbone._blocks.16._expand_conv', 'backbone._blocks.16._depthwise_conv', 'backbone._blocks.16._se_reduce', 'backbone._blocks.16._se_expand', 'backbone._blocks.16._project_conv', 'backbone._blocks.17._expand_conv', 'backbone._blocks.17._depthwise_conv', 'backbone._blocks.17._se_reduce', 'backbone._blocks.17._se_expand', 'backbone._blocks.17._project_conv', 'backbone._blocks.18._expand_conv', 'backbone._blocks.18._depthwise_conv', 'backbone._blocks.18._se_reduce', 'backbone._blocks.18._se_expand', 'backbone._blocks.18._project_conv', 'backbone._blocks.19._expand_conv', 'backbone._blocks.19._depthwise_conv', 'backbone._blocks.19._se_reduce', 'backbone._blocks.19._se_expand', 'backbone._blocks.19._project_conv', 'backbone._blocks.20._expand_conv', 'backbone._blocks.20._depthwise_conv', 'backbone._blocks.20._se_reduce', 'backbone._blocks.20._se_expand', 'backbone._blocks.20._project_conv', 'backbone._blocks.21._expand_conv', 'backbone._blocks.21._depthwise_conv', 'backbone._blocks.21._se_reduce', 'backbone._blocks.21._se_expand', 'backbone._blocks.21._project_conv', 'backbone._blocks.22._expand_conv', 'backbone._blocks.22._depthwise_conv', 'backbone._blocks.22._se_reduce', 'backbone._blocks.22._se_expand', 'backbone._blocks.22._project_conv', 'backbone._blocks.23._expand_conv', 'backbone._blocks.23._depthwise_conv', 'backbone._blocks.23._se_reduce', 'backbone._blocks.23._se_expand', 'backbone._blocks.23._project_conv', 'backbone._blocks.24._expand_conv', 'backbone._blocks.24._depthwise_conv', 'backbone._blocks.24._se_reduce', 'backbone._blocks.24._se_expand', 'backbone._blocks.24._project_conv', 'backbone._blocks.25._expand_conv', 'backbone._blocks.25._depthwise_conv', 'backbone._blocks.25._se_reduce', 'backbone._blocks.25._se_expand', 'backbone._blocks.25._project_conv', 'backbone._blocks.26._expand_conv', 'backbone._blocks.26._depthwise_conv', 'backbone._blocks.26._se_reduce', 'backbone._blocks.26._se_expand', 'backbone._blocks.26._project_conv', 'backbone._blocks.27._expand_conv', 'backbone._blocks.27._depthwise_conv', 'backbone._blocks.27._se_reduce', 'backbone._blocks.27._se_expand', 'backbone._blocks.27._project_conv', 'backbone._blocks.28._expand_conv', 'backbone._blocks.28._depthwise_conv', 'backbone._blocks.28._se_reduce', 'backbone._blocks.28._se_expand', 'backbone._blocks.28._project_conv', 'backbone._blocks.29._expand_conv', 'backbone._blocks.29._depthwise_conv', 'backbone._blocks.29._se_reduce', 'backbone._blocks.29._se_expand', 'backbone._blocks.29._project_conv', 'backbone._blocks.30._expand_conv', 'backbone._blocks.30._depthwise_conv', 'backbone._blocks.30._se_reduce', 'backbone._blocks.30._se_expand', 'backbone._blocks.30._project_conv', 'backbone._blocks.31._expand_conv', 'backbone._blocks.31._depthwise_conv', 'backbone._blocks.31._se_reduce', 'backbone._blocks.31._se_expand', 'backbone._blocks.31._project_conv', 'backbone._conv_head', 'backbone._fc', 'reconstruction.transformer.decoder.layers.0.self_attn.out_proj', 'reconstruction.transformer.decoder.layers.0.multihead_attn.out_proj', 'reconstruction.transformer.decoder.layers.0.linear1', 'reconstruction.transformer.decoder.layers.0.linear2', 'reconstruction.transformer.decoder.layers.1.self_attn.out_proj', 'reconstruction.transformer.decoder.layers.1.multihead_attn.out_proj', 'reconstruction.transformer.decoder.layers.1.linear1', 'reconstruction.transformer.decoder.layers.1.linear2', 'reconstruction.transformer.decoder.layers.2.self_attn.out_proj', 'reconstruction.transformer.decoder.layers.2.multihead_attn.out_proj', 'reconstruction.transformer.decoder.layers.2.linear1', 'reconstruction.transformer.decoder.layers.2.linear2', 'reconstruction.transformer.decoder.layers.3.self_attn.out_proj', 'reconstruction.transformer.decoder.layers.3.multihead_attn.out_proj', 'reconstruction.transformer.decoder.layers.3.linear1', 'reconstruction.transformer.decoder.layers.3.linear2', 'reconstruction.transformer.decoder.layers.4.self_attn.out_proj', 'reconstruction.transformer.decoder.layers.4.multihead_attn.out_proj', 'reconstruction.transformer.decoder.layers.4.linear1', 'reconstruction.transformer.decoder.layers.4.linear2', 'reconstruction.transformer.decoder.layers.5.self_attn.out_proj', 'reconstruction.transformer.decoder.layers.5.multihead_attn.out_proj', 'reconstruction.transformer.decoder.layers.5.linear1', 'reconstruction.transformer.decoder.layers.5.linear2', 'reconstruction.transformer.decoder.layers.6.self_attn.out_proj', 'reconstruction.transformer.decoder.layers.6.multihead_attn.out_proj', 'reconstruction.transformer.decoder.layers.6.linear1', 'reconstruction.transformer.decoder.layers.6.linear2', 'reconstruction.transformer.decoder.layers.7.self_attn.out_proj', 'reconstruction.transformer.decoder.layers.7.multihead_attn.out_proj', 'reconstruction.transformer.decoder.layers.7.linear1', 'reconstruction.transformer.decoder.layers.7.linear2', 'reconstruction.task_proj', 'reconstruction.input_proj', 'reconstruction.rec_head']\n",
      "Creating masks for current task...\n",
      "=== CL_Transformer 마스킹 분석 ===\n",
      "레이어: backbone._conv_stem.weight\n",
      "  전체 파라미터: 1,296\n",
      "  마스킹된 파라미터: 1,037 (80.02%)\n",
      "  활성화된 파라미터: 259 (19.98%)\n",
      "레이어: backbone._blocks.0._depthwise_conv.weight\n",
      "  전체 파라미터: 432\n",
      "  마스킹된 파라미터: 346 (80.09%)\n",
      "  활성화된 파라미터: 86 (19.91%)\n",
      "레이어: backbone._blocks.0._se_reduce.weight\n",
      "  전체 파라미터: 576\n",
      "  마스킹된 파라미터: 461 (80.03%)\n",
      "  활성화된 파라미터: 115 (19.97%)\n",
      "레이어: backbone._blocks.0._se_expand.weight\n",
      "  전체 파라미터: 576\n",
      "  마스킹된 파라미터: 461 (80.03%)\n",
      "  활성화된 파라미터: 115 (19.97%)\n",
      "레이어: backbone._blocks.0._project_conv.weight\n",
      "  전체 파라미터: 1,152\n",
      "  마스킹된 파라미터: 922 (80.03%)\n",
      "  활성화된 파라미터: 230 (19.97%)\n",
      "레이어: backbone._blocks.1._depthwise_conv.weight\n",
      "  전체 파라미터: 216\n",
      "  마스킹된 파라미터: 173 (80.09%)\n",
      "  활성화된 파라미터: 43 (19.91%)\n",
      "레이어: backbone._blocks.1._se_reduce.weight\n",
      "  전체 파라미터: 144\n",
      "  마스킹된 파라미터: 116 (80.56%)\n",
      "  활성화된 파라미터: 28 (19.44%)\n",
      "레이어: backbone._blocks.1._se_expand.weight\n",
      "  전체 파라미터: 144\n",
      "  마스킹된 파라미터: 116 (80.56%)\n",
      "  활성화된 파라미터: 28 (19.44%)\n",
      "레이어: backbone._blocks.1._project_conv.weight\n",
      "  전체 파라미터: 576\n",
      "  마스킹된 파라미터: 461 (80.03%)\n",
      "  활성화된 파라미터: 115 (19.97%)\n",
      "레이어: backbone._blocks.2._expand_conv.weight\n",
      "  전체 파라미터: 3,456\n",
      "  마스킹된 파라미터: 2,765 (80.01%)\n",
      "  활성화된 파라미터: 691 (19.99%)\n",
      "레이어: backbone._blocks.2._depthwise_conv.weight\n",
      "  전체 파라미터: 1,296\n",
      "  마스킹된 파라미터: 1,037 (80.02%)\n",
      "  활성화된 파라미터: 259 (19.98%)\n",
      "레이어: backbone._blocks.2._se_reduce.weight\n",
      "  전체 파라미터: 864\n",
      "  마스킹된 파라미터: 692 (80.09%)\n",
      "  활성화된 파라미터: 172 (19.91%)\n",
      "레이어: backbone._blocks.2._se_expand.weight\n",
      "  전체 파라미터: 864\n",
      "  마스킹된 파라미터: 692 (80.09%)\n",
      "  활성화된 파라미터: 172 (19.91%)\n",
      "레이어: backbone._blocks.2._project_conv.weight\n",
      "  전체 파라미터: 4,608\n",
      "  마스킹된 파라미터: 3,687 (80.01%)\n",
      "  활성화된 파라미터: 921 (19.99%)\n",
      "레이어: backbone._blocks.3._expand_conv.weight\n",
      "  전체 파라미터: 6,144\n",
      "  마스킹된 파라미터: 4,916 (80.01%)\n",
      "  활성화된 파라미터: 1,228 (19.99%)\n",
      "레이어: backbone._blocks.3._depthwise_conv.weight\n",
      "  전체 파라미터: 1,728\n",
      "  마스킹된 파라미터: 1,383 (80.03%)\n",
      "  활성화된 파라미터: 345 (19.97%)\n",
      "레이어: backbone._blocks.3._se_reduce.weight\n",
      "  전체 파라미터: 1,536\n",
      "  마스킹된 파라미터: 1,229 (80.01%)\n",
      "  활성화된 파라미터: 307 (19.99%)\n",
      "레이어: backbone._blocks.3._se_expand.weight\n",
      "  전체 파라미터: 1,536\n",
      "  마스킹된 파라미터: 1,229 (80.01%)\n",
      "  활성화된 파라미터: 307 (19.99%)\n",
      "레이어: backbone._blocks.3._project_conv.weight\n",
      "  전체 파라미터: 6,144\n",
      "  마스킹된 파라미터: 4,916 (80.01%)\n",
      "  활성화된 파라미터: 1,228 (19.99%)\n",
      "레이어: backbone._blocks.4._expand_conv.weight\n",
      "  전체 파라미터: 6,144\n",
      "  마스킹된 파라미터: 4,916 (80.01%)\n",
      "  활성화된 파라미터: 1,228 (19.99%)\n",
      "레이어: backbone._blocks.4._depthwise_conv.weight\n",
      "  전체 파라미터: 1,728\n",
      "  마스킹된 파라미터: 1,383 (80.03%)\n",
      "  활성화된 파라미터: 345 (19.97%)\n",
      "레이어: backbone._blocks.4._se_reduce.weight\n",
      "  전체 파라미터: 1,536\n",
      "  마스킹된 파라미터: 1,229 (80.01%)\n",
      "  활성화된 파라미터: 307 (19.99%)\n",
      "레이어: backbone._blocks.4._se_expand.weight\n",
      "  전체 파라미터: 1,536\n",
      "  마스킹된 파라미터: 1,229 (80.01%)\n",
      "  활성화된 파라미터: 307 (19.99%)\n",
      "레이어: backbone._blocks.4._project_conv.weight\n",
      "  전체 파라미터: 6,144\n",
      "  마스킹된 파라미터: 4,916 (80.01%)\n",
      "  활성화된 파라미터: 1,228 (19.99%)\n",
      "레이어: backbone._blocks.5._expand_conv.weight\n",
      "  전체 파라미터: 6,144\n",
      "  마스킹된 파라미터: 4,916 (80.01%)\n",
      "  활성화된 파라미터: 1,228 (19.99%)\n",
      "레이어: backbone._blocks.5._depthwise_conv.weight\n",
      "  전체 파라미터: 1,728\n",
      "  마스킹된 파라미터: 1,383 (80.03%)\n",
      "  활성화된 파라미터: 345 (19.97%)\n",
      "레이어: backbone._blocks.5._se_reduce.weight\n",
      "  전체 파라미터: 1,536\n",
      "  마스킹된 파라미터: 1,229 (80.01%)\n",
      "  활성화된 파라미터: 307 (19.99%)\n",
      "레이어: backbone._blocks.5._se_expand.weight\n",
      "  전체 파라미터: 1,536\n",
      "  마스킹된 파라미터: 1,229 (80.01%)\n",
      "  활성화된 파라미터: 307 (19.99%)\n",
      "레이어: backbone._blocks.5._project_conv.weight\n",
      "  전체 파라미터: 6,144\n",
      "  마스킹된 파라미터: 4,916 (80.01%)\n",
      "  활성화된 파라미터: 1,228 (19.99%)\n",
      "레이어: backbone._blocks.6._expand_conv.weight\n",
      "  전체 파라미터: 6,144\n",
      "  마스킹된 파라미터: 4,916 (80.01%)\n",
      "  활성화된 파라미터: 1,228 (19.99%)\n",
      "레이어: backbone._blocks.6._depthwise_conv.weight\n",
      "  전체 파라미터: 4,800\n",
      "  마스킹된 파라미터: 3,841 (80.02%)\n",
      "  활성화된 파라미터: 959 (19.98%)\n",
      "레이어: backbone._blocks.6._se_reduce.weight\n",
      "  전체 파라미터: 1,536\n",
      "  마스킹된 파라미터: 1,229 (80.01%)\n",
      "  활성화된 파라미터: 307 (19.99%)\n",
      "레이어: backbone._blocks.6._se_expand.weight\n",
      "  전체 파라미터: 1,536\n",
      "  마스킹된 파라미터: 1,229 (80.01%)\n",
      "  활성화된 파라미터: 307 (19.99%)\n",
      "레이어: backbone._blocks.6._project_conv.weight\n",
      "  전체 파라미터: 10,752\n",
      "  마스킹된 파라미터: 8,602 (80.00%)\n",
      "  활성화된 파라미터: 2,150 (20.00%)\n",
      "레이어: backbone._blocks.7._expand_conv.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.7._depthwise_conv.weight\n",
      "  전체 파라미터: 8,400\n",
      "  마스킹된 파라미터: 6,721 (80.01%)\n",
      "  활성화된 파라미터: 1,679 (19.99%)\n",
      "레이어: backbone._blocks.7._se_reduce.weight\n",
      "  전체 파라미터: 4,704\n",
      "  마스킹된 파라미터: 3,764 (80.02%)\n",
      "  활성화된 파라미터: 940 (19.98%)\n",
      "레이어: backbone._blocks.7._se_expand.weight\n",
      "  전체 파라미터: 4,704\n",
      "  마스킹된 파라미터: 3,764 (80.02%)\n",
      "  활성화된 파라미터: 940 (19.98%)\n",
      "레이어: backbone._blocks.7._project_conv.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.8._expand_conv.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.8._depthwise_conv.weight\n",
      "  전체 파라미터: 8,400\n",
      "  마스킹된 파라미터: 6,721 (80.01%)\n",
      "  활성화된 파라미터: 1,679 (19.99%)\n",
      "레이어: backbone._blocks.8._se_reduce.weight\n",
      "  전체 파라미터: 4,704\n",
      "  마스킹된 파라미터: 3,764 (80.02%)\n",
      "  활성화된 파라미터: 940 (19.98%)\n",
      "레이어: backbone._blocks.8._se_expand.weight\n",
      "  전체 파라미터: 4,704\n",
      "  마스킹된 파라미터: 3,764 (80.02%)\n",
      "  활성화된 파라미터: 940 (19.98%)\n",
      "레이어: backbone._blocks.8._project_conv.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.9._expand_conv.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.9._depthwise_conv.weight\n",
      "  전체 파라미터: 8,400\n",
      "  마스킹된 파라미터: 6,721 (80.01%)\n",
      "  활성화된 파라미터: 1,679 (19.99%)\n",
      "레이어: backbone._blocks.9._se_reduce.weight\n",
      "  전체 파라미터: 4,704\n",
      "  마스킹된 파라미터: 3,764 (80.02%)\n",
      "  활성화된 파라미터: 940 (19.98%)\n",
      "레이어: backbone._blocks.9._se_expand.weight\n",
      "  전체 파라미터: 4,704\n",
      "  마스킹된 파라미터: 3,764 (80.02%)\n",
      "  활성화된 파라미터: 940 (19.98%)\n",
      "레이어: backbone._blocks.9._project_conv.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.10._expand_conv.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.10._depthwise_conv.weight\n",
      "  전체 파라미터: 3,024\n",
      "  마스킹된 파라미터: 2,420 (80.03%)\n",
      "  활성화된 파라미터: 604 (19.97%)\n",
      "레이어: backbone._blocks.10._se_reduce.weight\n",
      "  전체 파라미터: 4,704\n",
      "  마스킹된 파라미터: 3,764 (80.02%)\n",
      "  활성화된 파라미터: 940 (19.98%)\n",
      "레이어: backbone._blocks.10._se_expand.weight\n",
      "  전체 파라미터: 4,704\n",
      "  마스킹된 파라미터: 3,764 (80.02%)\n",
      "  활성화된 파라미터: 940 (19.98%)\n",
      "레이어: backbone._blocks.10._project_conv.weight\n",
      "  전체 파라미터: 37,632\n",
      "  마스킹된 파라미터: 30,106 (80.00%)\n",
      "  활성화된 파라미터: 7,526 (20.00%)\n",
      "레이어: backbone._blocks.11._expand_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.11._depthwise_conv.weight\n",
      "  전체 파라미터: 6,048\n",
      "  마스킹된 파라미터: 4,839 (80.01%)\n",
      "  활성화된 파라미터: 1,209 (19.99%)\n",
      "레이어: backbone._blocks.11._se_reduce.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.11._se_expand.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.11._project_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.12._expand_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.12._depthwise_conv.weight\n",
      "  전체 파라미터: 6,048\n",
      "  마스킹된 파라미터: 4,839 (80.01%)\n",
      "  활성화된 파라미터: 1,209 (19.99%)\n",
      "레이어: backbone._blocks.12._se_reduce.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.12._se_expand.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.12._project_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.13._expand_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.13._depthwise_conv.weight\n",
      "  전체 파라미터: 6,048\n",
      "  마스킹된 파라미터: 4,839 (80.01%)\n",
      "  활성화된 파라미터: 1,209 (19.99%)\n",
      "레이어: backbone._blocks.13._se_reduce.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.13._se_expand.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.13._project_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.14._expand_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.14._depthwise_conv.weight\n",
      "  전체 파라미터: 6,048\n",
      "  마스킹된 파라미터: 4,839 (80.01%)\n",
      "  활성화된 파라미터: 1,209 (19.99%)\n",
      "레이어: backbone._blocks.14._se_reduce.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.14._se_expand.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.14._project_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.15._expand_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.15._depthwise_conv.weight\n",
      "  전체 파라미터: 6,048\n",
      "  마스킹된 파라미터: 4,839 (80.01%)\n",
      "  활성화된 파라미터: 1,209 (19.99%)\n",
      "레이어: backbone._blocks.15._se_reduce.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.15._se_expand.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.15._project_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.16._expand_conv.weight\n",
      "  전체 파라미터: 75,264\n",
      "  마스킹된 파라미터: 60,212 (80.00%)\n",
      "  활성화된 파라미터: 15,052 (20.00%)\n",
      "레이어: backbone._blocks.16._depthwise_conv.weight\n",
      "  전체 파라미터: 16,800\n",
      "  마스킹된 파라미터: 13,441 (80.01%)\n",
      "  활성화된 파라미터: 3,359 (19.99%)\n",
      "레이어: backbone._blocks.16._se_reduce.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.16._se_expand.weight\n",
      "  전체 파라미터: 18,816\n",
      "  마스킹된 파라미터: 15,053 (80.00%)\n",
      "  활성화된 파라미터: 3,763 (20.00%)\n",
      "레이어: backbone._blocks.16._project_conv.weight\n",
      "  전체 파라미터: 107,520\n",
      "  마스킹된 파라미터: 86,017 (80.00%)\n",
      "  활성화된 파라미터: 21,503 (20.00%)\n",
      "레이어: backbone._blocks.17._expand_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.17._depthwise_conv.weight\n",
      "  전체 파라미터: 24,000\n",
      "  마스킹된 파라미터: 19,201 (80.00%)\n",
      "  활성화된 파라미터: 4,799 (20.00%)\n",
      "레이어: backbone._blocks.17._se_reduce.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.17._se_expand.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.17._project_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.18._expand_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.18._depthwise_conv.weight\n",
      "  전체 파라미터: 24,000\n",
      "  마스킹된 파라미터: 19,201 (80.00%)\n",
      "  활성화된 파라미터: 4,799 (20.00%)\n",
      "레이어: backbone._blocks.18._se_reduce.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.18._se_expand.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.18._project_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.19._expand_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.19._depthwise_conv.weight\n",
      "  전체 파라미터: 24,000\n",
      "  마스킹된 파라미터: 19,201 (80.00%)\n",
      "  활성화된 파라미터: 4,799 (20.00%)\n",
      "레이어: backbone._blocks.19._se_reduce.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.19._se_expand.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.19._project_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.20._expand_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.20._depthwise_conv.weight\n",
      "  전체 파라미터: 24,000\n",
      "  마스킹된 파라미터: 19,201 (80.00%)\n",
      "  활성화된 파라미터: 4,799 (20.00%)\n",
      "레이어: backbone._blocks.20._se_reduce.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.20._se_expand.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.20._project_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.21._expand_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.21._depthwise_conv.weight\n",
      "  전체 파라미터: 24,000\n",
      "  마스킹된 파라미터: 19,201 (80.00%)\n",
      "  활성화된 파라미터: 4,799 (20.00%)\n",
      "레이어: backbone._blocks.21._se_reduce.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.21._se_expand.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.21._project_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.22._expand_conv.weight\n",
      "  전체 파라미터: 153,600\n",
      "  마스킹된 파라미터: 122,881 (80.00%)\n",
      "  활성화된 파라미터: 30,719 (20.00%)\n",
      "레이어: backbone._blocks.22._depthwise_conv.weight\n",
      "  전체 파라미터: 24,000\n",
      "  마스킹된 파라미터: 19,201 (80.00%)\n",
      "  활성화된 파라미터: 4,799 (20.00%)\n",
      "레이어: backbone._blocks.22._se_reduce.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.22._se_expand.weight\n",
      "  전체 파라미터: 38,400\n",
      "  마스킹된 파라미터: 30,721 (80.00%)\n",
      "  활성화된 파라미터: 7,679 (20.00%)\n",
      "레이어: backbone._blocks.22._project_conv.weight\n",
      "  전체 파라미터: 261,120\n",
      "  마스킹된 파라미터: 208,897 (80.00%)\n",
      "  활성화된 파라미터: 52,223 (20.00%)\n",
      "레이어: backbone._blocks.23._expand_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.23._depthwise_conv.weight\n",
      "  전체 파라미터: 40,800\n",
      "  마스킹된 파라미터: 32,641 (80.00%)\n",
      "  활성화된 파라미터: 8,159 (20.00%)\n",
      "레이어: backbone._blocks.23._se_reduce.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.23._se_expand.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.23._project_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.24._expand_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.24._depthwise_conv.weight\n",
      "  전체 파라미터: 40,800\n",
      "  마스킹된 파라미터: 32,641 (80.00%)\n",
      "  활성화된 파라미터: 8,159 (20.00%)\n",
      "레이어: backbone._blocks.24._se_reduce.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.24._se_expand.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.24._project_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.25._expand_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.25._depthwise_conv.weight\n",
      "  전체 파라미터: 40,800\n",
      "  마스킹된 파라미터: 32,641 (80.00%)\n",
      "  활성화된 파라미터: 8,159 (20.00%)\n",
      "레이어: backbone._blocks.25._se_reduce.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.25._se_expand.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.25._project_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.26._expand_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.26._depthwise_conv.weight\n",
      "  전체 파라미터: 40,800\n",
      "  마스킹된 파라미터: 32,641 (80.00%)\n",
      "  활성화된 파라미터: 8,159 (20.00%)\n",
      "레이어: backbone._blocks.26._se_reduce.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.26._se_expand.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.26._project_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.27._expand_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.27._depthwise_conv.weight\n",
      "  전체 파라미터: 40,800\n",
      "  마스킹된 파라미터: 32,641 (80.00%)\n",
      "  활성화된 파라미터: 8,159 (20.00%)\n",
      "레이어: backbone._blocks.27._se_reduce.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.27._se_expand.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.27._project_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.28._expand_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.28._depthwise_conv.weight\n",
      "  전체 파라미터: 40,800\n",
      "  마스킹된 파라미터: 32,641 (80.00%)\n",
      "  활성화된 파라미터: 8,159 (20.00%)\n",
      "레이어: backbone._blocks.28._se_reduce.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.28._se_expand.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.28._project_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.29._expand_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.29._depthwise_conv.weight\n",
      "  전체 파라미터: 40,800\n",
      "  마스킹된 파라미터: 32,641 (80.00%)\n",
      "  활성화된 파라미터: 8,159 (20.00%)\n",
      "레이어: backbone._blocks.29._se_reduce.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.29._se_expand.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.29._project_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.30._expand_conv.weight\n",
      "  전체 파라미터: 443,904\n",
      "  마스킹된 파라미터: 355,124 (80.00%)\n",
      "  활성화된 파라미터: 88,780 (20.00%)\n",
      "레이어: backbone._blocks.30._depthwise_conv.weight\n",
      "  전체 파라미터: 14,688\n",
      "  마스킹된 파라미터: 11,751 (80.00%)\n",
      "  활성화된 파라미터: 2,937 (20.00%)\n",
      "레이어: backbone._blocks.30._se_reduce.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.30._se_expand.weight\n",
      "  전체 파라미터: 110,976\n",
      "  마스킹된 파라미터: 88,781 (80.00%)\n",
      "  활성화된 파라미터: 22,195 (20.00%)\n",
      "레이어: backbone._blocks.30._project_conv.weight\n",
      "  전체 파라미터: 731,136\n",
      "  마스킹된 파라미터: 584,909 (80.00%)\n",
      "  활성화된 파라미터: 146,227 (20.00%)\n",
      "레이어: backbone._blocks.31._expand_conv.weight\n",
      "  전체 파라미터: 1,204,224\n",
      "  마스킹된 파라미터: 963,380 (80.00%)\n",
      "  활성화된 파라미터: 240,844 (20.00%)\n",
      "레이어: backbone._blocks.31._depthwise_conv.weight\n",
      "  전체 파라미터: 24,192\n",
      "  마스킹된 파라미터: 19,354 (80.00%)\n",
      "  활성화된 파라미터: 4,838 (20.00%)\n",
      "레이어: backbone._blocks.31._se_reduce.weight\n",
      "  전체 파라미터: 301,056\n",
      "  마스킹된 파라미터: 240,845 (80.00%)\n",
      "  활성화된 파라미터: 60,211 (20.00%)\n",
      "레이어: backbone._blocks.31._se_expand.weight\n",
      "  전체 파라미터: 301,056\n",
      "  마스킹된 파라미터: 240,845 (80.00%)\n",
      "  활성화된 파라미터: 60,211 (20.00%)\n",
      "레이어: backbone._blocks.31._project_conv.weight\n",
      "  전체 파라미터: 1,204,224\n",
      "  마스킹된 파라미터: 963,380 (80.00%)\n",
      "  활성화된 파라미터: 240,844 (20.00%)\n",
      "레이어: backbone._conv_head.weight\n",
      "  전체 파라미터: 802,816\n",
      "  마스킹된 파라미터: 642,253 (80.00%)\n",
      "  활성화된 파라미터: 160,563 (20.00%)\n",
      "레이어: backbone._fc.weight\n",
      "  전체 파라미터: 1,792,000\n",
      "  마스킹된 파라미터: 1,433,601 (80.00%)\n",
      "  활성화된 파라미터: 358,399 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.0.self_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.0.multihead_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.0.linear1.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.0.linear2.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.1.self_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.1.multihead_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.1.linear1.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.1.linear2.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.2.self_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.2.multihead_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.2.linear1.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.2.linear2.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.3.self_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.3.multihead_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.3.linear1.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.3.linear2.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.4.self_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.4.multihead_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.4.linear1.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.4.linear2.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.5.self_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.5.multihead_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.5.linear1.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.5.linear2.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.6.self_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.6.multihead_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.6.linear1.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.6.linear2.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.7.self_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.7.multihead_attn.out_proj.weight\n",
      "  전체 파라미터: 65,536\n",
      "  마스킹된 파라미터: 52,429 (80.00%)\n",
      "  활성화된 파라미터: 13,107 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.7.linear1.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.transformer.decoder.layers.7.linear2.weight\n",
      "  전체 파라미터: 262,144\n",
      "  마스킹된 파라미터: 209,716 (80.00%)\n",
      "  활성화된 파라미터: 52,428 (20.00%)\n",
      "레이어: reconstruction.task_proj.weight\n",
      "  전체 파라미터: 32,768\n",
      "  마스킹된 파라미터: 26,215 (80.00%)\n",
      "  활성화된 파라미터: 6,553 (20.00%)\n",
      "레이어: reconstruction.input_proj.weight\n",
      "  전체 파라미터: 69,632\n",
      "  마스킹된 파라미터: 55,706 (80.00%)\n",
      "  활성화된 파라미터: 13,926 (20.00%)\n",
      "레이어: reconstruction.rec_head.weight\n",
      "  전체 파라미터: 69,632\n",
      "  마스킹된 파라미터: 48,743 (70.00%)\n",
      "  활성화된 파라미터: 20,889 (30.00%)\n",
      "\n",
      "=== 모듈별 마스킹 통계 ===\n",
      "모듈: backbone\n",
      "  전체 파라미터: 19,186,376\n",
      "  마스킹된 파라미터: 15,349,202 (80.00%)\n",
      "  활성화된 파라미터: 3,837,174 (20.00%)\n",
      "모듈: reconstruction\n",
      "  전체 파라미터: 5,414,912\n",
      "  마스킹된 파라미터: 4,324,984 (79.87%)\n",
      "  활성화된 파라미터: 1,089,928 (20.13%)\n",
      "\n",
      "=== 전체 마스킹 통계 ===\n",
      "전체 파라미터: 24,601,288\n",
      "마스킹된 파라미터: 19,674,186 (79.97%)\n",
      "활성화된 파라미터: 4,927,102 (20.03%)\n",
      "\n",
      "=== Sparsity 설정 ===\n",
      "기본 스파시티: 0.8\n",
      "레이어별 스파시티 설정:\n",
      "  reconstruction.rec_head: 0.7\n"
     ]
    }
   ],
   "source": [
    "from CL import CL_Transformer\n",
    "sparsity_config = cfg.CONTINUAL.method.params\n",
    "\n",
    "cl_manager = CL_Transformer(model, accelerator.device, sparsity_config, replace_percentage=0.2)\n",
    "\n",
    "\n",
    "# 마스킹된 파라미터 분석\n",
    "def analyze_mask_distribution(cl_manager):\n",
    "    total_params = 0\n",
    "    masked_params = 0\n",
    "    layer_stats = {}\n",
    "    \n",
    "    print(\"=== CL_Transformer 마스킹 분석 ===\")\n",
    "    \n",
    "    for name, param in cl_manager.model.named_parameters():\n",
    "        if name in cl_manager.mask:\n",
    "            # 현재 레이어의 마스크 정보 가져오기\n",
    "            mask = cl_manager.mask[name]\n",
    "            total = param.numel()\n",
    "            masked = (mask == 0).sum().item()  # 0인 값(마스킹된 값)의 개수\n",
    "            active = (mask == 1).sum().item()  # 1인 값(활성화된 값)의 개수\n",
    "            \n",
    "            # 레이어 이름에서 가장 상위 모듈명 추출\n",
    "            module_name = name.split('.')[0]\n",
    "            if module_name not in layer_stats:\n",
    "                layer_stats[module_name] = {'total': 0, 'masked': 0, 'active': 0}\n",
    "            \n",
    "            # 통계 업데이트\n",
    "            layer_stats[module_name]['total'] += total\n",
    "            layer_stats[module_name]['masked'] += masked\n",
    "            layer_stats[module_name]['active'] += active\n",
    "            \n",
    "            total_params += total\n",
    "            masked_params += masked\n",
    "            \n",
    "            # 개별 레이어 정보 출력\n",
    "            print(f\"레이어: {name}\")\n",
    "            print(f\"  전체 파라미터: {total:,}\")\n",
    "            print(f\"  마스킹된 파라미터: {masked:,} ({masked/total*100:.2f}%)\")\n",
    "            print(f\"  활성화된 파라미터: {active:,} ({active/total*100:.2f}%)\")\n",
    "            \n",
    "    # 모듈별 통계 출력\n",
    "    print(\"\\n=== 모듈별 마스킹 통계 ===\")\n",
    "    for module_name, stats in layer_stats.items():\n",
    "        total = stats['total']\n",
    "        masked = stats['masked']\n",
    "        active = stats['active']\n",
    "        print(f\"모듈: {module_name}\")\n",
    "        print(f\"  전체 파라미터: {total:,}\")\n",
    "        print(f\"  마스킹된 파라미터: {masked:,} ({masked/total*100:.2f}%)\")\n",
    "        print(f\"  활성화된 파라미터: {active:,} ({active/total*100:.2f}%)\")\n",
    "    \n",
    "    # 전체 통계 출력\n",
    "    print(\"\\n=== 전체 마스킹 통계 ===\")\n",
    "    print(f\"전체 파라미터: {total_params:,}\")\n",
    "    print(f\"마스킹된 파라미터: {masked_params:,} ({masked_params/total_params*100:.2f}%)\")\n",
    "    print(f\"활성화된 파라미터: {total_params-masked_params:,} ({(total_params-masked_params)/total_params*100:.2f}%)\")\n",
    "    \n",
    "    # sparsity_config 설정 출력\n",
    "    print(\"\\n=== Sparsity 설정 ===\")\n",
    "    print(f\"기본 스파시티: {cl_manager.sparsity_config.get('default_sparsity', 'N/A')}\")\n",
    "    print(\"레이어별 스파시티 설정:\")\n",
    "    for layer, sparsity in cl_manager.sparsity_config.get('layer_specific', {}).items():\n",
    "        print(f\"  {layer}: {sparsity}\")\n",
    "    \n",
    "    return {\n",
    "        'total_params': total_params,\n",
    "        'masked_params': masked_params,\n",
    "        'layer_stats': layer_stats\n",
    "    }\n",
    "\n",
    "# 분석 실행\n",
    "mask_stats = analyze_mask_distribution(cl_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# --- inc_net.py 에서 가져온 CosineLinear (이전 답변의 간소화 버전 사용) ---\n",
    "class CosineLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, M_target_dim=None, use_RP=False, device='cuda'):\n",
    "        super(CosineLinear, self).__init__()\n",
    "        self.in_features_original = in_features\n",
    "        self.out_features = out_features\n",
    "        self.device = device\n",
    "        self.use_RP = use_RP\n",
    "        self.W_rand = None\n",
    "\n",
    "        current_in_features_for_weight = M_target_dim if use_RP and M_target_dim is not None and M_target_dim > 0 else in_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, current_in_features_for_weight).to(self.device))\n",
    "        self.sigma = nn.Parameter(torch.Tensor(1).to(self.device))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.sigma is not None:\n",
    "            self.sigma.data.fill_(1)\n",
    "\n",
    "    def forward(self, input_features_L):\n",
    "        if self.use_RP:\n",
    "            if self.W_rand is not None:\n",
    "                projected_features_M = F.relu(input_features_L @ self.W_rand)\n",
    "            else:\n",
    "                projected_features_M = input_features_L\n",
    "            logits = F.linear(projected_features_M, self.weight)\n",
    "        else:\n",
    "            normalized_input = F.normalize(input_features_L, p=2, dim=1)\n",
    "            normalized_weight = F.normalize(self.weight, p=2, dim=1)\n",
    "            logits = F.linear(normalized_input, normalized_weight)\n",
    "\n",
    "        if self.sigma is not None:\n",
    "            logits = self.sigma * logits\n",
    "        return {'logits': logits}\n",
    "\n",
    "class PatchRanPACAnomalyDetector:\n",
    "    def __init__(self, num_classes, original_feature_dim_L,\n",
    "                 M_target_dim=None, use_RP_flag=False, device='cuda'):\n",
    "        self.num_classes = num_classes # 정상 + 학습된 결함 유형 수\n",
    "        self.original_feature_dim_L = original_feature_dim_L\n",
    "        self.M_target_dim = M_target_dim\n",
    "        self.use_RP_flag = use_RP_flag\n",
    "        self.device = device\n",
    "\n",
    "        self.W_rand = None\n",
    "        self.fc_layer = CosineLinear(\n",
    "            in_features=self.original_feature_dim_L,\n",
    "            out_features=self.num_classes,\n",
    "            M_target_dim=self.M_target_dim,\n",
    "            use_RP=self.use_RP_flag,\n",
    "            device=self.device\n",
    "        ).to(self.device)\n",
    "\n",
    "        if self.use_RP_flag and self.M_target_dim is not None and self.M_target_dim > 0:\n",
    "            self.W_rand = torch.randn(\n",
    "                self.original_feature_dim_L,\n",
    "                self.M_target_dim\n",
    "            ).to(self.device)\n",
    "            self.fc_layer.W_rand = self.W_rand\n",
    "        else:\n",
    "            self.fc_layer.W_rand = None\n",
    "\n",
    "        M_for_GQ = self.M_target_dim if (self.use_RP_flag and self.M_target_dim is not None and self.M_target_dim > 0) else self.original_feature_dim_L\n",
    "        self.G = torch.zeros(M_for_GQ, M_for_GQ).to(self.device)\n",
    "        self.Q = torch.zeros(M_for_GQ, self.num_classes).to(self.device)\n",
    "        # Wo는 train_ridge_regression_head를 통해 학습되어 self.fc_layer.weight에 설정됨\n",
    "\n",
    "    def _calculate_entropy(self, probabilities):\n",
    "        probabilities = probabilities + 1e-9\n",
    "        entropy = -torch.sum(probabilities * torch.log(probabilities), dim=-1)\n",
    "        return entropy\n",
    "\n",
    "    def _calculate_max_softmax_prob(self, probabilities):\n",
    "        max_prob, _ = torch.max(probabilities, dim=-1)\n",
    "        return max_prob\n",
    "    \n",
    "    def update_label_idx_mapping(self, list_of_image_labels):\n",
    "        if not hasattr(self, 'label_idx_mapping'):\n",
    "            self.label_idx_mapping = {}\n",
    "            \n",
    "        # Get unique labels from the current batch\n",
    "        unique_labels = torch.unique(list_of_image_labels)\n",
    "        \n",
    "        # Process each unique label\n",
    "        for label in unique_labels:\n",
    "            if label not in self.label_idx_mapping:\n",
    "                # If the label doesn't exist in the mapping, add it with the next available index\n",
    "                next_idx = len(self.label_idx_mapping)\n",
    "                self.label_idx_mapping[label.item()] = next_idx\n",
    "                print(f\"Added new label {label} with index {next_idx}\")\n",
    "        \n",
    "        print(f\"Current label mapping: {self.label_idx_mapping}\")\n",
    "\n",
    "    def train_ridge_regression_head(self, list_of_image_patch_features_L, list_of_image_labels):\n",
    "        \"\"\"\n",
    "        여러 이미지로부터 추출된 패치 특징들로 G, Q를 누적하고 Wo를 계산.\n",
    "        list_of_image_patch_features_L: 각 요소가 한 이미지의 (num_patches, L_dim) 패치 특징 텐서인 리스트.\n",
    "        list_of_image_labels: 각 요소가 해당 이미지의 클래스 레이블(스칼라)인 리스트.\n",
    "        \"\"\"\n",
    "        print(f\"\\n--- Training head with new batch of images ---\")\n",
    "        all_patches_H_for_task = []\n",
    "        all_patch_onehot_labels_for_task = []\n",
    "        \n",
    "        # Initialize label_idx_mapping if it doesn't exist                \n",
    "        self.update_label_idx_mapping(list_of_image_labels)\n",
    "        \n",
    "\n",
    "        for img_idx, image_patches_L in enumerate(list_of_image_patch_features_L):\n",
    "            image_label = self.label_idx_mapping[list_of_image_labels[img_idx].item()]\n",
    "            image_patches_L = image_patches_L.to(self.device) # (num_patches, L_dim)\n",
    "\n",
    "            # 현재 이미지의 모든 패치에 대해 RP 적용 (필요시)\n",
    "            if self.use_RP_flag and self.W_rand is not None:\n",
    "                image_patches_H = F.relu(image_patches_L @ self.W_rand) # (num_patches, M_dim)\n",
    "            else:\n",
    "                image_patches_H = image_patches_L # (num_patches, L_dim)\n",
    "\n",
    "            all_patches_H_for_task.append(image_patches_H)\n",
    "\n",
    "            # 모든 패치는 해당 이미지의 레이블을 상속\n",
    "            num_patches = image_patches_H.shape[0]\n",
    "            patch_labels = torch.full((num_patches,), image_label, dtype=torch.long, device=self.device)\n",
    "            patch_onehot_labels = F.one_hot(patch_labels, num_classes=self.num_classes).float()\n",
    "            all_patch_onehot_labels_for_task.append(patch_onehot_labels)\n",
    "\n",
    "        if not all_patches_H_for_task:\n",
    "            print(\"No patch features to process for training.\")\n",
    "            return None\n",
    "\n",
    "        # 현재 태스크(또는 배치)의 모든 패치 특징과 레이블을 하나로 합침\n",
    "        current_batch_all_patches_H = torch.cat(all_patches_H_for_task, dim=0)\n",
    "        current_batch_all_patch_onehot_labels = torch.cat(all_patch_onehot_labels_for_task, dim=0)\n",
    "\n",
    "        # 누적 통계량 G, Q 업데이트\n",
    "        self.G += current_batch_all_patches_H.T @ current_batch_all_patches_H\n",
    "        self.Q += current_batch_all_patches_H.T @ current_batch_all_patch_onehot_labels\n",
    "        print(f\"Updated G shape: {self.G.shape}, Updated Q shape: {self.Q.shape}\")\n",
    "\n",
    "        # Lambda 최적화 (RanPAC.py의 optimise_ridge_parameter 간소화 버전)\n",
    "        # 실제로는 현재 배치(current_batch_all_patches_H)의 일부를 검증용으로 사용해야 함\n",
    "        # 여기서는 현재 배치의 모든 패치 특징으로 lambda를 찾고, 전체 G,Q에 적용\n",
    "        current_task_lambda = self._optimise_ridge_for_current_batch(current_batch_all_patches_H, current_batch_all_patch_onehot_labels)\n",
    "\n",
    "        try:\n",
    "            current_G_dim = self.G.size(0)\n",
    "            Wo_final_transposed = torch.linalg.solve(\n",
    "                self.G + current_task_lambda * torch.eye(current_G_dim, device=self.device),\n",
    "                self.Q\n",
    "            )\n",
    "            Wo_final = Wo_final_transposed.T\n",
    "        except Exception as e:\n",
    "            print(f\"Error solving for Wo: {e}. Using pseudo-inverse.\")\n",
    "            G_reg = self.G + current_task_lambda * torch.eye(self.G.size(0), device=self.device)\n",
    "            Wo_final_transposed = torch.linalg.lstsq(G_reg, self.Q).solution\n",
    "            Wo_final = Wo_final_transposed.T\n",
    "\n",
    "        if Wo_final is not None:\n",
    "            self.fc_layer.weight.data = Wo_final\n",
    "            print(f\"Updated fc_layer weight with Wo, shape: {self.fc_layer.weight.data.shape}\")\n",
    "        return Wo_final\n",
    "\n",
    "    def _optimise_ridge_for_current_batch(self, H_features_batch, Y_onehot_batch, ridges=None):\n",
    "        \"\"\" 현재 배치의 특징과 레이블로 lambda 최적화 \"\"\"\n",
    "        if ridges is None: ridges = 10.0**np.arange(-3, 4)\n",
    "        num_samples = H_features_batch.shape[0]\n",
    "        if num_samples < 20: return 1.0 # 샘플 부족 시 기본값\n",
    "\n",
    "        perm = torch.randperm(num_samples, device=self.device)\n",
    "        H_shuffled, Y_shuffled = H_features_batch[perm], Y_onehot_batch[perm]\n",
    "        split_idx = int(num_samples * 0.8)\n",
    "        if split_idx == 0 or split_idx == num_samples: return 1.0\n",
    "\n",
    "        H_train, H_val = H_shuffled[:split_idx], H_shuffled[split_idx:]\n",
    "        Y_train, Y_val = Y_shuffled[:split_idx], Y_shuffled[split_idx:]\n",
    "        if H_train.shape[0] == 0 or H_val.shape[0] == 0: return 1.0\n",
    "\n",
    "        Q_train_batch = H_train.T @ Y_train\n",
    "        G_train_batch = H_train.T @ H_train\n",
    "        best_lambda, min_mse = ridges[0], float('inf')\n",
    "\n",
    "        for ridge_lambda in ridges:\n",
    "            try:\n",
    "                Wo_temp = torch.linalg.solve(\n",
    "                    G_train_batch + ridge_lambda * torch.eye(G_train_batch.size(0), device=self.device),\n",
    "                    Q_train_batch)\n",
    "                Y_pred_val = H_val @ Wo_temp\n",
    "                mse = F.mse_loss(Y_pred_val, Y_val)\n",
    "                if mse < min_mse: min_mse, best_lambda = mse, ridge_lambda\n",
    "            except: continue\n",
    "        print(f\"Optimal lambda for current batch: {best_lambda} (MSE: {min_mse:.4f})\")\n",
    "        return best_lambda\n",
    "\n",
    "    def predict_image_anomaly(self, image_patches_L, alpha=0.5, beta=0.5, aggregation_method='max'):\n",
    "        \"\"\"\n",
    "        한 이미지의 패치 특징들(L차원)을 입력받아 이미지 레벨의 이상 점수와 예측을 반환.\n",
    "        image_patches_L: (num_patches, L_dim) 텐서.\n",
    "        aggregation_method: 'max' 또는 'mean'으로 패치 점수 집계 방식 선택.\n",
    "        \"\"\"\n",
    "        self.fc_layer.eval()\n",
    "        if image_patches_L.ndim == 2: # 단일 이미지의 패치들 (num_patches, L_dim)\n",
    "            image_patches_L = image_patches_L.unsqueeze(0) # (1, num_patches, L_dim)으로 만듦\n",
    "\n",
    "        batch_size, num_patches, _ = image_patches_L.shape\n",
    "        # 모든 패치를 하나의 배치로 처리하기 위해 reshape\n",
    "        # (batch_size * num_patches, L_dim)\n",
    "        flat_patches_L = image_patches_L.reshape(-1, self.original_feature_dim_L).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 1. 로짓 계산 (CosineLinear 내부에서 RP 자동 처리)\n",
    "            output_dict = self.fc_layer(flat_patches_L)\n",
    "            patch_logits = output_dict['logits'] # (B*num_patches, num_classes)\n",
    "\n",
    "            # 2. 소프트맥스 확률 및 관련 지표 계산\n",
    "            patch_probabilities = F.softmax(patch_logits, dim=-1)\n",
    "            patch_predicted_classes = torch.argmax(patch_probabilities, dim=-1)\n",
    "            patch_entropy = self._calculate_entropy(patch_probabilities)\n",
    "            patch_confidence = self._calculate_max_softmax_prob(patch_probabilities)\n",
    "\n",
    "            # 3. 각 패치에 대한 결합 이상 점수\n",
    "            # patch_anomaly_scores_combined = alpha * (1 - patch_confidence) + beta * patch_entropy\n",
    "            patch_anomaly_scores_combined = 1 - patch_confidence\n",
    "\n",
    "\n",
    "            # 4. 이미지 레벨로 집계\n",
    "            # (batch_size, num_patches) 형태로 다시 reshape\n",
    "            patch_anomaly_scores_combined_reshaped = patch_anomaly_scores_combined.reshape(batch_size, num_patches)\n",
    "            patch_predicted_classes_reshaped = patch_predicted_classes.reshape(batch_size, num_patches)\n",
    "            patch_entropy_reshaped = patch_entropy.reshape(batch_size, num_patches)\n",
    "            patch_confidence_reshaped = patch_confidence.reshape(batch_size, num_patches)\n",
    "\n",
    "            if aggregation_method == 'max':\n",
    "                image_level_anomaly_score = torch.max(patch_anomaly_scores_combined_reshaped, dim=1)[0]\n",
    "                # 이미지 레벨 예측은 가장 높은 이상 점수를 가진 패치의 예측 클래스를 따르거나,\n",
    "                # 또는 패치 예측들의 다수결(mode)을 따를 수 있음. 여기서는 가장 이상한 패치 기준.\n",
    "                # 또는 \"정상\" 클래스(예: 0)가 아닌 다른 클래스로 예측된 패치가 하나라도 있으면 해당 결함으로 판단.\n",
    "                # 아래는 예시: 가장 높은 이상 점수를 가진 패치의 예측 클래스를 이미지 레벨 예측으로.\n",
    "                indices_max_anomaly_patch = torch.argmax(patch_anomaly_scores_combined_reshaped, dim=1)\n",
    "                image_level_predicted_class = patch_predicted_classes_reshaped[torch.arange(batch_size), indices_max_anomaly_patch]\n",
    "\n",
    "            elif aggregation_method == 'mean':\n",
    "                image_level_anomaly_score = torch.mean(patch_anomaly_scores_combined_reshaped, dim=1)\n",
    "                # 평균 점수 사용 시 이미지 레벨 클래스 예측은 더 복잡할 수 있음 (예: 패치 예측의 최빈값)\n",
    "                image_level_predicted_class = torch.mode(patch_predicted_classes_reshaped, dim=1)[0]\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported aggregation_method.\")\n",
    "\n",
    "        # 패치별 상세 정보도 반환하여 anomaly localization 등에 활용 가능\n",
    "        return {\n",
    "            \"image_level_anomaly_score\": image_level_anomaly_score, # (batch_size,)\n",
    "            \"image_level_predicted_class\": image_level_predicted_class, # (batch_size,)\n",
    "            \"patch_level_predicted_classes\": patch_predicted_classes_reshaped, # (batch_size, num_patches)\n",
    "            \"patch_level_anomaly_scores\": patch_anomaly_scores_combined_reshaped, # (batch_size, num_patches)\n",
    "            \"patch_level_entropy\": patch_entropy_reshaped, # (batch_size, num_patches)\n",
    "            \"patch_level_confidence\": patch_confidence_reshaped # (batch_size, num_patches)\n",
    "        }\n",
    "        \n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "class RescaleSegmentor:\n",
    "    def __init__(self, device, target_size=224):\n",
    "        self.device = device\n",
    "        self.target_size = target_size\n",
    "        self.smoothing = 4\n",
    "\n",
    "    def convert_to_segmentation(self, patch_scores):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if isinstance(patch_scores, np.ndarray):\n",
    "                patch_scores = torch.from_numpy(patch_scores)\n",
    "            _scores = patch_scores.to(self.device)\n",
    "            _scores = _scores.unsqueeze(1)\n",
    "            _scores = F.interpolate(\n",
    "                _scores, size=self.target_size, mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "            _scores = _scores.squeeze(1)\n",
    "            patch_scores = _scores.cpu().numpy()\n",
    "\n",
    "        return [\n",
    "            ndimage.gaussian_filter(patch_score, sigma=self.smoothing)\n",
    "            for patch_score in patch_scores\n",
    "        ]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import MetricCalculator, loco_auroc\n",
    "model.eval()\n",
    "img_level = MetricCalculator(metric_list = ['auroc','average_precision'])\n",
    "pix_level = MetricCalculator(metric_list = ['auroc','average_precision'])\n",
    "cls_level = MetricCalculator(metric_list = ['auroc','average_precision'])\n",
    "segmentor = RescaleSegmentor(device='cuda')\n",
    "\n",
    "# 모델 설정 파라미터\n",
    "ORIGINAL_FEATURE_DIM_L = 768\n",
    "PROJECTION_DIM_M = 12000 # M > L\n",
    "USE_RP = True\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 데이터셋에서 클래스 수 동적으로 파악\n",
    "unique_classes = set()\n",
    "for class_name, loaders in loader_dict.items():\n",
    "    trainloader = loaders['train']\n",
    "    for _, _, cls in trainloader:\n",
    "        unique_classes.update(cls.numpy())\n",
    "NUM_CLASSES_TOTAL = len(unique_classes)\n",
    "print(f\"Detected {NUM_CLASSES_TOTAL} unique classes in the dataset\")\n",
    "\n",
    "# 1. Detector 객체 생성\n",
    "detector = PatchRanPACAnomalyDetector(\n",
    "    num_classes=NUM_CLASSES_TOTAL,\n",
    "    original_feature_dim_L=ORIGINAL_FEATURE_DIM_L,\n",
    "    M_target_dim=PROJECTION_DIM_M,\n",
    "    use_RP_flag=USE_RP,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# 2. 학습 데이터 생성 (이미지별 패치 특징 리스트)\n",
    "with torch.no_grad():\n",
    "    # Continual learning을 위해 loader_dict에서 순차적으로 trainloader 받아옴\n",
    "    for class_name, loaders in loader_dict.items():\n",
    "        trainloader = loaders['train']\n",
    "        \n",
    "        outputs_list = [] \n",
    "        cls_list = [] \n",
    "        for imgs, labels, cls in trainloader:\n",
    "            outputs = model.embed_img(imgs.to('cuda'))\n",
    "            outputs_list.append(outputs.detach().cpu())\n",
    "            cls_list.append(cls.detach().cpu())\n",
    "\n",
    "        cls_list = torch.concat(cls_list)\n",
    "        outputs_list = torch.concat(outputs_list)\n",
    "\n",
    "        # 각 클래스별로 continual learning 수행\n",
    "        detector.train_ridge_regression_head(outputs_list, cls_list)\n",
    "        print(f\"Trained detector on class: {class_name}\")\n",
    "\n",
    "    # 테스트 데이터로 평가\n",
    "    for img, label, class_label, gts in testloader:\n",
    "        patches_L = model.embed_img(img.to('cuda'))    \n",
    "        results = detector.predict_image_anomaly(patches_L, aggregation_method='max')\n",
    "        \n",
    "        score, score_map = results['image_level_anomaly_score'], results['patch_level_anomaly_scores']\n",
    "        score_map = np.array(segmentor.convert_to_segmentation(score_map.unsqueeze(-1)))\n",
    "        \n",
    "        pix_level.update(score_map, gts.type(torch.int))\n",
    "        img_level.update(score, label.type(torch.int))\n",
    "        cls_level.update(results['image_level_predicted_class'], pd.Series(class_label.numpy()).map(detector.label_idx_mapping).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 각 클래스별로 테스트 데이터 평가\n",
    "for class_name, loaders in loader_dict.items():\n",
    "    testloader = loaders['test']\n",
    "    print(f\"Testing on class: {class_name}\")\n",
    "    \n",
    "    for img, label, class_label, gts in testloader:\n",
    "        patches_L = model.embed_img(img.to('cuda'))    \n",
    "        results = detector.predict_image_anomaly(patches_L, aggregation_method='max')\n",
    "        \n",
    "        score, score_map = results['image_level_anomaly_score'], results['patch_level_anomaly_scores']\n",
    "        score_map = np.array(segmentor.convert_to_segmentation(score_map.unsqueeze(-1)))\n",
    "        \n",
    "        pix_level.update(score_map, gts.type(torch.int))\n",
    "        img_level.update(score, label.type(torch.int))\n",
    "        cls_level.update(results['image_level_predicted_class'], pd.Series(class_label.numpy()).map(detector.label_idx_mapping).values)\n",
    "\n",
    "# 모든 레벨에 대한 메트릭 계산\n",
    "i_results, p_results = img_level.compute(), pix_level.compute()\n",
    "\n",
    "# 이미지 레벨 및 픽셀 레벨 메트릭 결과 출력\n",
    "print(f\"Image-level metrics: AUROC: {i_results['auroc']:.3f}, AP: {i_results['average_precision']:.3f}\")\n",
    "print(f\"Pixel-level metrics: AUROC: {p_results['auroc']:.3f}, AP: {p_results['average_precision']:.3f}\")\n",
    "\n",
    "# 클래스 분류 메트릭을 위해 classification_report 사용\n",
    "preds = np.concatenate(cls_level.preds)\n",
    "targets = np.concatenate(cls_level.targets)\n",
    "print(\"\\nClass-level classification report:\")\n",
    "print(classification_report(targets, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Experiment Name : test-all-continual-scheduler-Continual_True-online_False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from PIL import Image \n",
    "from arguments import parser \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "from datasets import create_dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from utils.metrics import MetricCalculator, loco_auroc\n",
    "from accelerate import Accelerator\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns \n",
    "from main import torch_seed\n",
    "\n",
    "\n",
    "torch_seed(42)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' \n",
    "default_setting = './configs/default/mvtecad_15.yaml'\n",
    "model_setting = './configs/model/simplenet.yaml'\n",
    "cfg = parser(True,default_setting, model_setting)\n",
    "\n",
    "model  = __import__('models').__dict__[cfg.MODEL.method](\n",
    "        backbone = cfg.MODEL.backbone,\n",
    "        **cfg.MODEL.params\n",
    "        ).to('cuda')\n",
    "\n",
    "loader_dict = {}\n",
    "accelerator = Accelerator()\n",
    "for cn in cfg.DATASET.class_names:\n",
    "    trainset, testset = create_dataset(\n",
    "        dataset_name  = cfg.DATASET.dataset_name,\n",
    "        datadir       = cfg.DATASET.datadir,\n",
    "        class_name    = cn,\n",
    "        img_size      = cfg.DATASET.img_size,\n",
    "        mean          = cfg.DATASET.mean,\n",
    "        std           = cfg.DATASET.std,\n",
    "        aug_info      = cfg.DATASET.aug_info,\n",
    "        **cfg.DATASET.get('params',{})\n",
    "    )\n",
    "    trainloader = DataLoader(\n",
    "        dataset     = trainset,\n",
    "        batch_size  = cfg.DATASET.batch_size,\n",
    "        num_workers = cfg.DATASET.num_workers,\n",
    "        shuffle     = True \n",
    "    )    \n",
    "\n",
    "    testloader = DataLoader(\n",
    "            dataset     = testset,\n",
    "            batch_size  = 8,\n",
    "            num_workers = cfg.DATASET.num_workers,\n",
    "            shuffle     = False \n",
    "        )    \n",
    "    \n",
    "    loader_dict[cn] = {'train':trainloader,'test':testloader}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = model \n",
    "\n",
    "for images, label, class_label, gts in testloader:\n",
    "    images = images.to('cuda')\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = self._embed(img, evaluation=False)[0]\n",
    "true_feats = self.pre_projection(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 28, 28])\n",
      "torch.Size([8, 1024, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "features = self.forward_modules[\"feature_aggregator\"](images)\n",
    "features = [features[layer] for layer in self.layers_to_extract_from]\n",
    "for f in features:\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 28, 28])\n",
      "torch.Size([8, 1024, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "for i, feat in enumerate(features):\n",
    "    if len(feat.shape) == 3:\n",
    "        B, L, C = feat.shape\n",
    "        features[i] = feat.reshape(B, int(math.sqrt(L)), int(math.sqrt(L)), C).permute(0, 3, 1, 2)\n",
    "\n",
    "for f in features:\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 784, 512, 3, 3])\n",
      "torch.Size([8, 196, 1024, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "            self.patch_maker.patchify(x, return_spatial_info=True) for x in features\n",
    "        ]\n",
    "features = [x[0] for x in features]\n",
    "for f in features:\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "from timm import create_model\n",
    "\n",
    "class VitBackbone(torch.nn.Module):\n",
    "    def __init__(self, model_name='vit_base_patch16_224.orig_in21k', device='cuda'):\n",
    "        super(VitBackbone, self).__init__()\n",
    "        self.model = create_model(model_name, pretrained=True).to(device)\n",
    "        \n",
    "        # Set all parameters to non-trainable\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x, layers_to_extract=None):\n",
    "        if layers_to_extract is None:\n",
    "            # Default: extract features from all transformer blocks\n",
    "            layers_to_extract = list(range(len(self.model.blocks)))\n",
    "        \n",
    "        # Initial processing\n",
    "        x = self.model.patch_embed(x)\n",
    "        \n",
    "        # Add positional embedding without cls token\n",
    "        if hasattr(self.model, 'pos_embed'):\n",
    "            # Skip the class token position (index 0)\n",
    "            pos_embed = self.model.pos_embed[:, 1:, :]\n",
    "            x = x + pos_embed\n",
    "        \n",
    "        x = self.model.pos_drop(x)\n",
    "        \n",
    "        # Store intermediate features\n",
    "        features = []        \n",
    "        # Process through transformer blocks\n",
    "        for i, block in enumerate(self.model.blocks):\n",
    "            x = block(x)\n",
    "            if i in layers_to_extract:\n",
    "                features.append(x)\n",
    "        \n",
    "        # Process features to correct shape\n",
    "        for j in range(len(features)):\n",
    "            B, PxP, C = features[j].shape\n",
    "            \n",
    "            # Calculate P (assuming square patches)\n",
    "            P = int(PxP ** 0.5)\n",
    "            \n",
    "            # Reshape to spatial format\n",
    "            features[j] = einops.rearrange(features[j], 'b (h w) c -> b c h w', h=P, w=P)\n",
    "            \n",
    "        return features\n",
    "\n",
    "\n",
    "# Create backbone and extract features\n",
    "backbone = VitBackbone().to('cuda')\n",
    "features = backbone(images, layers_to_extract=[3, 6, 9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
