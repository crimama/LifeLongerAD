{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "from PIL import Image \n",
    "from arguments import parser \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "from datasets import create_dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from utils.metrics import MetricCalculator, loco_auroc\n",
    "from accelerate import Accelerator\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns \n",
    "from main import torch_seed\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.manifold import TSNE \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "torch_seed(42)\n",
    "exp_dir = '/Volume/VAD/LifeLongerAD_cu121/results/CFGCAD/MVTecAD/baseline6_200epoch-3_5_with_5_step-Continual_True-online_False/seed_42/'\n",
    "cfg_dir = os.path.join(exp_dir,'configs.yaml')\n",
    "cfg = OmegaConf.load(cfg_dir)\n",
    "\n",
    "\n",
    "model  = __import__('models').__dict__[cfg.MODEL.method](\n",
    "        backbone = cfg.MODEL.backbone,\n",
    "        **cfg.MODEL.params\n",
    "        ).to('cuda')\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "loader_dict = {}\n",
    "accelerator = Accelerator()\n",
    "for cn in cfg.DATASET.class_names:\n",
    "    trainset, testset = create_dataset(\n",
    "        dataset_name  = cfg.DATASET.dataset_name,\n",
    "        datadir       = cfg.DATASET.datadir,\n",
    "        class_name    = cn,\n",
    "        img_size      = cfg.DATASET.img_size,\n",
    "        mean          = cfg.DATASET.mean,\n",
    "        std           = cfg.DATASET.std,\n",
    "        aug_info      = cfg.DATASET.aug_info,\n",
    "        **cfg.DATASET.get('params',{})\n",
    "    )\n",
    "    trainloader = DataLoader(\n",
    "        dataset     = trainset,\n",
    "        batch_size  = cfg.DATASET.batch_size,\n",
    "        num_workers = cfg.DATASET.num_workers,\n",
    "        shuffle     = True \n",
    "    )    \n",
    "\n",
    "    testloader = DataLoader(\n",
    "            dataset     = testset,\n",
    "            batch_size  = 2,\n",
    "            num_workers = cfg.DATASET.num_workers,\n",
    "            shuffle     = False \n",
    "        )    \n",
    "    \n",
    "    loader_dict[cn] = {'train':trainloader,'test':testloader}    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3_5_with_5_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_features(model,test_loader):\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "\n",
    "    backbone = model.backbone\n",
    "    neck = model.neck \n",
    "    reconstruction = model.reconstruction \n",
    "\n",
    "    output_encoder_list = [] \n",
    "    with torch.no_grad():\n",
    "        align = [] \n",
    "        recon = [] \n",
    "        cls_list = [] \n",
    "        label_list = [] \n",
    "        for step, (images, labels, class_labels, gts) in enumerate(test_loader):\n",
    "            Input = {'image':images.to('cuda'),'clslabel':class_labels.to('cuda')}\n",
    "            cls_list.append(class_labels.numpy())\n",
    "            label_list.append(labels.numpy())\n",
    "            \n",
    "            \n",
    "            task_id = Input.get('clslabel')\n",
    "            \n",
    "                \n",
    "            output = backbone(Input)            \n",
    "            Input.update(output)\n",
    "            \n",
    "            output = neck(Input)\n",
    "            Input.update(output)\n",
    "            \n",
    "            #! output = reconstruction(Input)\n",
    "            self = reconstruction \n",
    "            \n",
    "            feature_align = Input['feature_align']\n",
    "            src, pos_embed = self.forward_pre(feature_align)\n",
    "            \n",
    "            B = feature_align.shape[0]\n",
    "                \n",
    "            uncond_mask = torch.rand(B, device=device) < self.uncond_prob\n",
    "            masked_task_id = task_id.clone()\n",
    "            masked_task_id[uncond_mask] = self.null_token_idx\n",
    "\n",
    "            task_emb = self.task_embedding(masked_task_id) # B, D_cfg\n",
    "            task_emb_proj = self.task_proj(task_emb) # B, D_feat\n",
    "            task_embedding = task_emb_proj.unsqueeze(0)\n",
    "                                    \n",
    "            #! output_decoder, _ = self.transformer(src, pos_embed, task_emb_proj.unsqueeze(0)) # mask 인자 필요시 추가\n",
    "            self = self.transformer\n",
    "            \n",
    "            target_size = (14, 14)        \n",
    "            \n",
    "            \n",
    "            _, batch_size, _ = src.shape\n",
    "            pos_embed = torch.cat(\n",
    "                [pos_embed.unsqueeze(1)] * batch_size, dim=1\n",
    "            )  # (H X W) x B x C\n",
    "\n",
    "            if self.neighbor_mask:\n",
    "                mask = self.generate_mask(\n",
    "                    self.feature_size, self.neighbor_mask.neighbor_size\n",
    "                )\n",
    "                mask_enc = mask if self.neighbor_mask.mask[0] else None\n",
    "                mask_dec1 = mask if self.neighbor_mask.mask[1] else None\n",
    "                mask_dec2 = mask if self.neighbor_mask.mask[2] else None\n",
    "            else:\n",
    "                mask_enc = mask_dec1 = mask_dec2 = None\n",
    "\n",
    "            output_encoder, task_embedding = self.encoder(\n",
    "                src, mask=mask_enc, pos=pos_embed,  task_embedding=task_embedding\n",
    "            )  # (H X W) x B x C\n",
    "            \n",
    "            \n",
    "            \n",
    "            output_encoder_list.append(output_encoder.detach().cpu().numpy())\n",
    "            \n",
    "            output = reconstruction(Input)\n",
    "            Input.update(output)            \n",
    "            \n",
    "    output_encoder_list = np.concatenate(output_encoder_list,1).mean(0)\n",
    "    cls_list = np.concatenate(cls_list)\n",
    "    label_list = np.concatenate(label_list)\n",
    "    \n",
    "    return output_encoder_list, cls_list, label_list \n",
    "\n",
    "def get_in_out_feature(model,test_loader):\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        align = [] \n",
    "        recon = [] \n",
    "        for step, (images, labels, class_labels, gts) in enumerate(test_loader):\n",
    "            Input = {'image':images.to('cuda'),'clslabel':class_labels.to('cuda')}\n",
    "            outputs = model(Input) \n",
    "            align.append(outputs['feature_align'].detach().cpu().numpy())\n",
    "            recon.append(outputs['feature_rec'].detach().cpu().numpy())        \n",
    "            \n",
    "    align = np.vstack(align).mean(3).mean(2)\n",
    "    recon = np.vstack(recon).mean(3).mean(2)\n",
    "    \n",
    "    return align, recon\n",
    "\n",
    "def get_df(feature, cls_list, label_list):\n",
    "    feature = pd.DataFrame(feature)\n",
    "    feature['cls_name'] = cls_list \n",
    "    feature['label'] = label_list \n",
    "    return feature \n",
    "\n",
    "def get_tsne(feature):\n",
    "    tsne = TSNE() \n",
    "    feature = tsne.fit_transform(feature)\n",
    "    return feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스타일 설정\n",
    "sns.set_style('whitegrid')\n",
    "fig, axes = plt.subplots(2,3, figsize=(18,6))\n",
    "\n",
    "\n",
    "for j,n in enumerate([0,4]):\n",
    "    cn = cfg.DATASET.class_names[0]\n",
    "    test_loader = loader_dict[cn]['test']\n",
    "    \n",
    "    cn = cfg.DATASET.class_names[n]\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            os.path.join(exp_dir,'model_weight',f'{cn}_model.pth')\n",
    "        )\n",
    "    )    \n",
    "    model = model.cuda()\n",
    "\n",
    "    output_encoder_list, cls_list, label_list  = get_output_features(model, test_loader)\n",
    "    align, recon = get_in_out_feature(model, test_loader)\n",
    "    \n",
    "    align = get_tsne(align)\n",
    "    recon = get_tsne(recon)\n",
    "    output_encoder_list = get_tsne(output_encoder_list)\n",
    "    align_re, recon_re, enc_re = [get_df(f,cls_list, label_list) for f in [align, recon, output_encoder_list]]    \n",
    "\n",
    "\n",
    "    unique_labels = align_re['label'].unique()\n",
    "    marker_list = ['*', 's']  # 필요 개수만큼 늘려주세요\n",
    "    marker_dict = dict(zip(unique_labels, marker_list))\n",
    "\n",
    "    for i, data in enumerate([align_re,enc_re,recon_re]):\n",
    "        sns.scatterplot(\n",
    "            x=0, y=1,\n",
    "            hue='cls_name',         # 색깔 매핑\n",
    "            style='label',          # 모양 매핑\n",
    "            markers=marker_dict,    # label별 모양 사전\n",
    "            palette='tab10',\n",
    "            s=60,\n",
    "            alpha=0.75,\n",
    "            edgecolor='k',\n",
    "            linewidth=0.7,\n",
    "            data=data,\n",
    "            ax=axes[j,i],\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "        axes[j,i].set_xlabel('Embedding 1', fontsize=12)\n",
    "        # ax.set_ylabel('Embedding 2', fontsize=12)\n",
    "\n",
    "plt.tight_layout(pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10_1_5_with_5step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "from PIL import Image \n",
    "from arguments import parser \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "from datasets import create_dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from utils.metrics import MetricCalculator, loco_auroc\n",
    "from accelerate import Accelerator\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns \n",
    "from main import torch_seed\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.manifold import TSNE \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "torch_seed(42)\n",
    "exp_dir = '/Volume/VAD/LifeLongerAD_cu121/results/CFGCAD/MVTecAD/baseline6_200epoch-10_1_with_5_step-Continual_True-online_False/seed_42/'\n",
    "cfg_dir = os.path.join(exp_dir,'configs.yaml')\n",
    "cfg = OmegaConf.load(cfg_dir)\n",
    "\n",
    "\n",
    "model  = __import__('models').__dict__[cfg.MODEL.method](\n",
    "        backbone = cfg.MODEL.backbone,\n",
    "        **cfg.MODEL.params\n",
    "        ).to('cuda')\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "loader_dict = {}\n",
    "accelerator = Accelerator()\n",
    "for cn in cfg.DATASET.class_names:\n",
    "    trainset, testset = create_dataset(\n",
    "        dataset_name  = cfg.DATASET.dataset_name,\n",
    "        datadir       = cfg.DATASET.datadir,\n",
    "        class_name    = cn,\n",
    "        img_size      = cfg.DATASET.img_size,\n",
    "        mean          = cfg.DATASET.mean,\n",
    "        std           = cfg.DATASET.std,\n",
    "        aug_info      = cfg.DATASET.aug_info,\n",
    "        **cfg.DATASET.get('params',{})\n",
    "    )\n",
    "    trainloader = DataLoader(\n",
    "        dataset     = trainset,\n",
    "        batch_size  = cfg.DATASET.batch_size,\n",
    "        num_workers = cfg.DATASET.num_workers,\n",
    "        shuffle     = True \n",
    "    )    \n",
    "\n",
    "    testloader = DataLoader(\n",
    "            dataset     = testset,\n",
    "            batch_size  = 2,\n",
    "            num_workers = cfg.DATASET.num_workers,\n",
    "            shuffle     = False \n",
    "        )    \n",
    "    \n",
    "    loader_dict[cn] = {'train':trainloader,'test':testloader}    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_features(model,test_loader):\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "\n",
    "    backbone = model.backbone\n",
    "    neck = model.neck \n",
    "    reconstruction = model.reconstruction \n",
    "\n",
    "    output_encoder_list = [] \n",
    "    with torch.no_grad():\n",
    "        align = [] \n",
    "        recon = [] \n",
    "        cls_list = [] \n",
    "        label_list = [] \n",
    "        for step, (images, labels, class_labels, gts) in enumerate(test_loader):\n",
    "            Input = {'image':images.to('cuda'),'clslabel':class_labels.to('cuda')}\n",
    "            cls_list.append(class_labels.numpy())\n",
    "            label_list.append(labels.numpy())\n",
    "            \n",
    "            \n",
    "            task_id = Input.get('clslabel')\n",
    "            \n",
    "                \n",
    "            output = backbone(Input)            \n",
    "            Input.update(output)\n",
    "            \n",
    "            output = neck(Input)\n",
    "            Input.update(output)\n",
    "            \n",
    "            #! output = reconstruction(Input)\n",
    "            self = reconstruction \n",
    "            \n",
    "            feature_align = Input['feature_align']\n",
    "            src, pos_embed = self.forward_pre(feature_align)\n",
    "            \n",
    "            B = feature_align.shape[0]\n",
    "                \n",
    "            uncond_mask = torch.rand(B, device=device) < self.uncond_prob\n",
    "            masked_task_id = task_id.clone()\n",
    "            masked_task_id[uncond_mask] = self.null_token_idx\n",
    "\n",
    "            task_emb = self.task_embedding(masked_task_id) # B, D_cfg\n",
    "            task_emb_proj = self.task_proj(task_emb) # B, D_feat\n",
    "            task_embedding = task_emb_proj.unsqueeze(0)\n",
    "                                    \n",
    "            #! output_decoder, _ = self.transformer(src, pos_embed, task_emb_proj.unsqueeze(0)) # mask 인자 필요시 추가\n",
    "            self = self.transformer\n",
    "            \n",
    "            target_size = (14, 14)        \n",
    "            \n",
    "            \n",
    "            _, batch_size, _ = src.shape\n",
    "            pos_embed = torch.cat(\n",
    "                [pos_embed.unsqueeze(1)] * batch_size, dim=1\n",
    "            )  # (H X W) x B x C\n",
    "\n",
    "            if self.neighbor_mask:\n",
    "                mask = self.generate_mask(\n",
    "                    self.feature_size, self.neighbor_mask.neighbor_size\n",
    "                )\n",
    "                mask_enc = mask if self.neighbor_mask.mask[0] else None\n",
    "                mask_dec1 = mask if self.neighbor_mask.mask[1] else None\n",
    "                mask_dec2 = mask if self.neighbor_mask.mask[2] else None\n",
    "            else:\n",
    "                mask_enc = mask_dec1 = mask_dec2 = None\n",
    "\n",
    "            output_encoder, task_embedding = self.encoder(\n",
    "                src, mask=mask_enc, pos=pos_embed,  task_embedding=task_embedding\n",
    "            )  # (H X W) x B x C\n",
    "            \n",
    "            \n",
    "            \n",
    "            output_encoder_list.append(output_encoder.detach().cpu().numpy())\n",
    "            \n",
    "            output = reconstruction(Input)\n",
    "            Input.update(output)            \n",
    "            \n",
    "    output_encoder_list = np.concatenate(output_encoder_list,1).mean(0)\n",
    "    cls_list = np.concatenate(cls_list)\n",
    "    label_list = np.concatenate(label_list)\n",
    "    \n",
    "    return output_encoder_list, cls_list, label_list \n",
    "\n",
    "def get_in_out_feature(model,test_loader):\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        align = [] \n",
    "        recon = [] \n",
    "        for step, (images, labels, class_labels, gts) in enumerate(test_loader):\n",
    "            Input = {'image':images.to('cuda'),'clslabel':class_labels.to('cuda')}\n",
    "            outputs = model(Input) \n",
    "            align.append(outputs['feature_align'].detach().cpu().numpy())\n",
    "            recon.append(outputs['feature_rec'].detach().cpu().numpy())        \n",
    "            \n",
    "    align = np.vstack(align).mean(3).mean(2)\n",
    "    recon = np.vstack(recon).mean(3).mean(2)\n",
    "    \n",
    "    return align, recon, outputs\n",
    "\n",
    "def get_df(feature, cls_list, label_list):\n",
    "    feature = pd.DataFrame(feature)\n",
    "    feature['cls_name'] = cls_list \n",
    "    feature['label'] = label_list \n",
    "    return feature \n",
    "\n",
    "def get_tsne(feature):\n",
    "    tsne = TSNE() \n",
    "    feature = tsne.fit_transform(feature)\n",
    "    return feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스타일 설정\n",
    "sns.set_style('whitegrid')\n",
    "fig, axes = plt.subplots(6,3, figsize=(24, 24))\n",
    "\n",
    "\n",
    "for n in range(len(loader_dict)):\n",
    "    cn = cfg.DATASET.class_names[0]\n",
    "    test_loader = loader_dict[cn]['test']\n",
    "\n",
    "    output_encoder_list, cls_list, label_list  = get_output_features(model, test_loader)\n",
    "    align, recon = get_in_out_feature(model, test_loader)\n",
    "\n",
    "    cn = cfg.DATASET.class_names[n]\n",
    "    model_weight = os.path.join(exp_dir,'model_weight',f'{cn}_model.pth')\n",
    "    weight = torch.load(model_weight)\n",
    "    model.load_state_dict(weight)    \n",
    "    model = model.cuda()\n",
    "\n",
    "    \n",
    "    align = get_tsne(align)\n",
    "    recon = get_tsne(recon)\n",
    "    output_encoder_list = get_tsne(output_encoder_list)\n",
    "    align_re, recon_re, enc_re = [get_df(f,cls_list, label_list) for f in [align, recon, output_encoder_list]]    \n",
    "\n",
    "\n",
    "    unique_labels = align_re['label'].unique()\n",
    "    marker_list = ['*', 's']  # 필요 개수만큼 늘려주세요\n",
    "    marker_dict = dict(zip(unique_labels, marker_list))\n",
    "\n",
    "    for i, data in enumerate([align_re,enc_re,recon_re]):\n",
    "        sns.scatterplot(\n",
    "            x=0, y=1,\n",
    "            hue='cls_name',         # 색깔 매핑\n",
    "            style='label',          # 모양 매핑\n",
    "            markers=marker_dict,    # label별 모양 사전\n",
    "            palette='tab10',\n",
    "            s=80,\n",
    "            alpha=0.75,\n",
    "            edgecolor='k',\n",
    "            linewidth=0.5,\n",
    "            data=data,\n",
    "            ax=axes[n,i]\n",
    "        )\n",
    "\n",
    "        axes[n,i].set_xlabel('Embedding 1', fontsize=12)\n",
    "        # ax.set_ylabel('Embedding 2', fontsize=12)\n",
    "\n",
    "        # 범례 위치 조정: 두 개의 범례(색깔·모양)를 따로 표시\n",
    "        if i == 1:\n",
    "            leg1 = axes[n,i].legend(title='Class (color)', loc='upper right')\n",
    "            axes[n,i].add_artist(leg1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "from PIL import Image \n",
    "from arguments import parser \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "from datasets import create_dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from utils.metrics import MetricCalculator, loco_auroc\n",
    "from accelerate import Accelerator\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns \n",
    "from main import torch_seed\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.manifold import TSNE \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "torch_seed(42)\n",
    "exp_dir = '/Volume/VAD/LifeLongerAD_cu121/results/CFGCAD/MVTecAD/baseline6_200epoch-10_1_with_5_step-Continual_True-online_False/seed_42/'\n",
    "cfg_dir = os.path.join(exp_dir,'configs.yaml')\n",
    "cfg = OmegaConf.load(cfg_dir)\n",
    "\n",
    "\n",
    "model  = __import__('models').__dict__[cfg.MODEL.method](\n",
    "        backbone = cfg.MODEL.backbone,\n",
    "        **cfg.MODEL.params\n",
    "        ).to('cuda')\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "loader_dict = {}\n",
    "accelerator = Accelerator()\n",
    "for cn in cfg.DATASET.class_names:\n",
    "    trainset, testset = create_dataset(\n",
    "        dataset_name  = cfg.DATASET.dataset_name,\n",
    "        datadir       = cfg.DATASET.datadir,\n",
    "        class_name    = cn,\n",
    "        img_size      = cfg.DATASET.img_size,\n",
    "        mean          = cfg.DATASET.mean,\n",
    "        std           = cfg.DATASET.std,\n",
    "        aug_info      = cfg.DATASET.aug_info,\n",
    "        **cfg.DATASET.get('params',{})\n",
    "    )\n",
    "    trainloader = DataLoader(\n",
    "        dataset     = trainset,\n",
    "        batch_size  = cfg.DATASET.batch_size,\n",
    "        num_workers = cfg.DATASET.num_workers,\n",
    "        shuffle     = True \n",
    "    )    \n",
    "\n",
    "    testloader = DataLoader(\n",
    "            dataset     = testset,\n",
    "            batch_size  = 2,\n",
    "            num_workers = cfg.DATASET.num_workers,\n",
    "            shuffle     = False \n",
    "        )    \n",
    "    \n",
    "    loader_dict[cn] = {'train':trainloader,'test':testloader}    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.cuda()\n",
    "\n",
    "backbone = model.backbone\n",
    "neck = model.neck \n",
    "reconstruction = model.reconstruction \n",
    "\n",
    "output_encoder_list = [] \n",
    "with torch.no_grad():\n",
    "    align = [] \n",
    "    recon = [] \n",
    "    cls_list = [] \n",
    "    label_list = [] \n",
    "    for step, (images, labels, class_labels, gts) in enumerate(testloader):\n",
    "        Input = {'image':images.to('cuda'),'clslabel':class_labels.to('cuda')}\n",
    "        cls_list.append(class_labels.numpy())\n",
    "        label_list.append(labels.numpy())\n",
    "        \n",
    "        \n",
    "        task_id = Input.get('clslabel')\n",
    "        \n",
    "            \n",
    "        output = backbone(Input)            \n",
    "        Input.update(output)\n",
    "        \n",
    "        output = neck(Input)\n",
    "        Input.update(output)\n",
    "        \n",
    "        #! output = reconstruction(Input)\n",
    "        self = reconstruction \n",
    "        \n",
    "        # feature_align = Input['feature_align']\n",
    "        # src, pos_embed = self.forward_pre(feature_align)\n",
    "        \n",
    "        # B = feature_align.shape[0]\n",
    "            \n",
    "        # uncond_mask = torch.rand(B, device=device) < self.uncond_prob\n",
    "        # masked_task_id = task_id.clone()\n",
    "        # masked_task_id[uncond_mask] = self.null_token_idx\n",
    "\n",
    "        # task_emb = self.task_embedding(masked_task_id) # B, D_cfg\n",
    "        # task_emb_proj = self.task_proj(task_emb) # B, D_feat\n",
    "        # task_embedding = task_emb_proj.unsqueeze(0)\n",
    "                                \n",
    "        # #! output_decoder, _ = self.transformer(src, pos_embed, task_emb_proj.unsqueeze(0)) # mask 인자 필요시 추가\n",
    "        # self = self.transformer\n",
    "        \n",
    "        # target_size = (14, 14)        \n",
    "        \n",
    "        \n",
    "        # _, batch_size, _ = src.shape\n",
    "        # pos_embed = torch.cat(\n",
    "        #     [pos_embed.unsqueeze(1)] * batch_size, dim=1\n",
    "        # )  # (H X W) x B x C\n",
    "\n",
    "        # if self.neighbor_mask:\n",
    "        #     mask = self.generate_mask(\n",
    "        #         self.feature_size, self.neighbor_mask.neighbor_size\n",
    "        #     )\n",
    "        #     mask_enc = mask if self.neighbor_mask.mask[0] else None\n",
    "        #     mask_dec1 = mask if self.neighbor_mask.mask[1] else None\n",
    "        #     mask_dec2 = mask if self.neighbor_mask.mask[2] else None\n",
    "        # else:\n",
    "        #     mask_enc = mask_dec1 = mask_dec2 = None\n",
    "\n",
    "        # output_encoder, task_embedding = self.encoder(\n",
    "        #     src, mask=mask_enc, pos=pos_embed,  task_embedding=task_embedding\n",
    "        # )  # (H X W) x B x C\n",
    "        \n",
    "        \n",
    "        \n",
    "        # output_encoder_list.append(output_encoder.detach().cpu().numpy())\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_align = Input['feature_align']\n",
    "model.reconstruction(Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reconstruction.rec_head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
