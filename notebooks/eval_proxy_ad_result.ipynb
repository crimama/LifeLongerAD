{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import re \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf \n",
    "from glob import glob \n",
    "os.chdir('../')\n",
    "\n",
    "def load_df(log_dir):\n",
    "    with open(log_dir, 'r') as f: \n",
    "        data = f.readlines()\n",
    "    df = pd.DataFrame(list(pd.Series(data).map(eval).values))    \n",
    "    return df \n",
    "\n",
    "def load_log_data(class_name, version, result_dir,method):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for i,v in enumerate(version):\n",
    "        log_dir = os.path.join(result_dir,class_name,method,v,'log.txt')\n",
    "        \n",
    "        temp_df = load_df(log_dir)\n",
    "        temp_df['hue'] = v \n",
    "        \n",
    "        df = pd.concat([df,temp_df])\n",
    "    \n",
    "    return df \n",
    "\n",
    "def plot_log(data,class_name, metrics:list, figsize:tuple = (10,7)):\n",
    "    \n",
    "    fig, axes = plt.subplots(len(metrics),1,figsize=figsize)\n",
    "    \n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        sns.lineplot(\n",
    "            x = 'epoch',\n",
    "            y = metric,\n",
    "            data = data,\n",
    "            hue = data['hue'],\n",
    "            ax = ax \n",
    "        )\n",
    "      \n",
    "    fig.suptitle(class_name)\n",
    "    plt.show()\n",
    "    \n",
    "def read_txt(log_dir):\n",
    "    with open(log_dir, 'r') as f: \n",
    "        data = f.readlines()    \n",
    "    df = pd.DataFrame([eval(d) for d in data]) \n",
    "    return df \n",
    "pd.options.display.float_format = '{: .3f}'.format \n",
    "\n",
    "def temperature_matching(x):\n",
    "    value = x.split('_')[-1]\n",
    "    \n",
    "    if value in ['BASELINE','focalloss']:\n",
    "        return 0.05 \n",
    "    elif value in ['T1','T2']:\n",
    "        return float(value[-1])\n",
    "    else:\n",
    "        if len(value) ==1:\n",
    "            return value \n",
    "        else:\n",
    "            return re.search(r'T_(\\d+\\.\\d+)', x).group(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 결과 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volume/VAD/ProxyCore/results/CoreInit/MVTecAD/wood/BASELINE_focalloss_augment_norm_core_coreset_init_T_0.05_sampling_ratio_0.25-anomaly_ratio_0.0/seed_0/configs.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3128e33bcab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'CoreInit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Sampling Ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mconfigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'configs.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0msampling_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sampling_ratio'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampling_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/omegaconf/omegaconf.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file_)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_yaml_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volume/VAD/ProxyCore/results/CoreInit/MVTecAD/wood/BASELINE_focalloss_augment_norm_core_coreset_init_T_0.05_sampling_ratio_0.25-anomaly_ratio_0.0/seed_0/configs.yaml'"
     ]
    }
   ],
   "source": [
    "version = ['*-anomaly_ratio_0.0']\n",
    "\n",
    "result_dir = './results'\n",
    "dataset = ''\n",
    "method = '*'\n",
    "\n",
    "# log_dirs = pd.Series(glob('/Volume/ProxyCore/results/*/*/*/*-anomaly_ratio_0.0/seed_0/result.txt'))\n",
    "\n",
    "log_dirs = pd.Series(glob('/Volume/VAD/ProxyCore/results/*/*/*/*-anomaly_ratio_0.0/seed_0/result.txt'))\n",
    "log_dirs = log_dirs[log_dirs.apply(lambda x : 'BASELINE' in x )].values\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for log_dir in log_dirs:\n",
    "    auroc_list = {}\n",
    "    method = log_dir.split('/')[-6]\n",
    "    dataset = log_dir.split('/')[-5]\n",
    "    class_name = log_dir.split('/')[-4]\n",
    "    exp_name = log_dir.split('/')[-3].split('-a')[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    data = load_df(log_dir)\n",
    "\n",
    "    met = [d['pix_level']['average_precision'] for d in data['test_metrics']]    \n",
    "        \n",
    "    idx = np.argmax(met)\n",
    "    \n",
    "    result = pd.DataFrame(data['test_metrics'][idx])\n",
    "    result = result.reset_index().melt(['index'])\n",
    "    result.columns = ['metric','level','value']\n",
    "    \n",
    "    if exp_name == 'baseline_yen':\n",
    "        method = 'softpatch-yen'\n",
    "    anomaly_ratio = float(log_dir.split('/')[-3].split('_')[-1])\n",
    "    \n",
    "    for c in ['method','dataset','class_name','exp_name','anomaly_ratio']:\n",
    "        result[c] = eval(c) \n",
    "    \n",
    "    # Coreinit Option \n",
    "    if method == 'CoreInit':\n",
    "        # Sampling Ratio \n",
    "        configs = OmegaConf.load(log_dir.replace('result.txt','configs.yaml'))\n",
    "        sampling_ratio = configs.MODEL.params.sampling_ratio\n",
    "        result['sampling_ratio'] = sampling_ratio \n",
    "        \n",
    "        if 'pslabel_sampling_ratio' in configs.MODEL.params:\n",
    "            pslabel_sampling_ratio = configs.MODEL.params.pslabel_sampling_ratio\n",
    "            result['pslabel_sampling_ratio'] = pslabel_sampling_ratio\n",
    "        else:\n",
    "            result['pslabel_sampling_ratio'] = sampling_ratio\n",
    "            \n",
    "        if 'temperature' in configs.MODEL.params:\n",
    "            result['Temperature'] = configs.MODEL.params.temperature\n",
    "        else:\n",
    "            result['Temperature'] = 0.05 \n",
    "        \n",
    "    df = pd.concat([df,result])\n",
    "\n",
    "df = df[df['metric'].apply(lambda x : x in ['auroc','loco_auroc','average_precision'])].reset_index(drop=True)\n",
    "df.loc[df['metric']=='loco_auroc','structural_anomalies'] = df[df['metric']=='loco_auroc']['value'].apply(lambda x : x['structural_anomalies'])\n",
    "df.loc[df['metric']=='loco_auroc','logical_anomalies'] = df[df['metric']=='loco_auroc']['value'].apply(lambda x : x['logical_anomalies'])\n",
    "\n",
    "# df = df.melt(['index','class','anomaly_ratio','exp_name'])\n",
    "# # exp_d = {'Proxy_single_base' : 'ProxyNCA', 'Proxy_single_anchor_loss':'Proxy anchor', 'Proxy_nsoftmax' : 'Proxy nSoftmax'}\n",
    "# # df['exp_name'] = df['exp_name'].map(exp_d)\n",
    "# ind_d = {'img_level':'Image Level', 'pix_level' : 'Pixel Level'}\n",
    "# df['index'] = df['index'].map(ind_d)\n",
    "\n",
    "exp = df[\n",
    "    (df['exp_name'].apply(lambda x : 'BASELINE' in x ))&\n",
    "    (df['exp_name'].apply(lambda x : x not in ['BASELINE_CosineAnnealingLR', 'BASELINE_LR', 'BASELINE_Temperature_more', 'BASELINE_Temperature'] ))&\n",
    "    (df['method']=='CoreInit')\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "exp['FocalLoss']    = exp['exp_name'].apply(lambda x : 'focalloss' if 'focalloss' in x else 'CrossEntropy')\n",
    "exp['Augmentation'] = exp['exp_name'].apply(lambda x : 'None' if 'no_augment' in x else 'Augment')\n",
    "exp['Label_core']   = exp['exp_name'].apply(lambda x : 'norm_core' if 'norm_core' in x else 'Core')\n",
    "exp['Proxy_init']   = exp['exp_name'].apply(lambda x : 'rand_init' if 'rand_init' in x else 'coreset_init')\n",
    "\n",
    "exp['method'] = 'CoreInit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "temp = torch.rand(32,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0007, 0.0011, 0.0006,  ..., 0.0015, 0.0006, 0.0011],\n",
       "        [0.0011, 0.0008, 0.0007,  ..., 0.0008, 0.0010, 0.0007],\n",
       "        [0.0006, 0.0014, 0.0011,  ..., 0.0011, 0.0007, 0.0012],\n",
       "        ...,\n",
       "        [0.0010, 0.0007, 0.0008,  ..., 0.0010, 0.0015, 0.0011],\n",
       "        [0.0015, 0.0014, 0.0006,  ..., 0.0007, 0.0009, 0.0015],\n",
       "        [0.0011, 0.0008, 0.0007,  ..., 0.0012, 0.0013, 0.0008]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(temp,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'MVTecAD'\n",
    "metric = 'average_precision'\n",
    "level = 'pix_level'\n",
    "\n",
    "index = ['class_name']\n",
    "columns = ['method']\n",
    "exp1= exp[\n",
    "     (exp['dataset']==dataset) &\n",
    "     (exp['Label_core']=='norm_core') & # norm_core, Core \n",
    "     (exp['FocalLoss']=='focalloss') & #CrossEntropy, focalloss \n",
    "     (exp['Proxy_init']=='coreset_init') & #rand_init coreset_init\n",
    "     (exp['Augmentation']=='Augment') &\n",
    "     (exp['Temperature']==0.1) &\n",
    "     (exp['metric']==metric) &\n",
    "     (exp['level']==level)\n",
    "     ].pivot_table(index=index,columns=columns,values='value',aggfunc='mean')\n",
    "\n",
    "base = df[\n",
    "    (df['exp_name'].apply(lambda x : 'BASELINE' in x ))&\n",
    "    (df['metric'].apply(lambda x : 'loco' not in x ))&\n",
    "    (df['method'] != 'CoreInit')\n",
    "    ].reset_index(drop=True).pivot_table(index=['class_name','level','dataset','metric','method'],columns=['exp_name'],values='value',aggfunc='max')\n",
    "base = base.reset_index().melt(id_vars=['class_name','level','dataset','metric','method'])\n",
    "\n",
    "base1= base[\n",
    "    (base['dataset']==dataset) &\n",
    "    (base['metric']==metric) &\n",
    "    (base['level']== level)\n",
    "].pivot_table(index=index,columns=columns,values='value')\n",
    "\n",
    "result = pd.concat([base1,exp1],axis=1)\n",
    "columns = ['FastFlow','ReverseDistillation','SPADE','PaDiM','PatchCore','CoreInit']\n",
    "#result.loc['Average'] = result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_name\n",
       "bottle        0.023\n",
       "cable         0.030\n",
       "capsule       0.016\n",
       "carpet        0.115\n",
       "grid          0.002\n",
       "hazelnut      0.021\n",
       "leather       0.056\n",
       "metal_nut     0.001\n",
       "pill         -0.025\n",
       "screw        -0.004\n",
       "tile          0.042\n",
       "toothbrush    0.027\n",
       "transistor   -0.021\n",
       "wood         -0.012\n",
       "zipper        0.016\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['CoreInit'] - result['PatchCore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'MVTecAD'\n",
    "metric = 'average_precision'\n",
    "level = 'pix_level'\n",
    "\n",
    "index = ['pslabel_sampling_ratio']\n",
    "columns = ['sampling_ratio']\n",
    "exp1 = exp[\n",
    "     (exp['dataset']==dataset) &\n",
    "     (exp['Label_core']=='norm_core') & # norm_core, Core \n",
    "     (exp['FocalLoss']=='focalloss') & #CrossEntropy, focalloss \n",
    "     (exp['Proxy_init']=='coreset_init') & #rand_init coreset_init\n",
    "     (exp['Augmentation']=='Augment') &\n",
    "     (exp['Temperature']==0.05) &\n",
    "     (exp['metric']==metric) &\n",
    "     (exp['level']==level)\n",
    "     ].pivot_table(index=index,columns=columns,values='value',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sampling_ratio</th>\n",
       "      <th>0.010</th>\n",
       "      <th>0.100</th>\n",
       "      <th>0.250</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pslabel_sampling_ratio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.250</th>\n",
       "      <td>0.634</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sampling_ratio          0.010  0.100  0.250\n",
       "pslabel_sampling_ratio                     \n",
       "0.010                   0.631    NaN    NaN\n",
       "0.100                     NaN  0.653    NaN\n",
       "0.250                   0.634  0.642  0.644"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
